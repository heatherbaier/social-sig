{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import sklearn\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "\n",
    "import socialSig\n",
    "importlib.reload(socialSig)\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sending_citizen_unspecified  sending_citizenship_unknown  \\\n",
      "0                  1134.995083                   243.827586   \n",
      "1                   917.067746                   600.000000   \n",
      "2                   637.977315                   557.150000   \n",
      "3                  1178.378744                  1678.562500   \n",
      "4                  2231.128863                  2916.538705   \n",
      "\n",
      "   sending_household_not_owned  sending_household_owned  \\\n",
      "0                  1178.209016              1106.832815   \n",
      "1                  1274.160656               795.118020   \n",
      "2                   729.454795               610.791414   \n",
      "3                  1560.244328              1084.109969   \n",
      "4                  2104.943216              2278.834178   \n",
      "\n",
      "   sending_household_owned_unknown  sending_indigeneity  sending_internet  \\\n",
      "0                       736.562500           918.960526       2111.233685   \n",
      "1                        -1.000000            -1.000000       1988.103175   \n",
      "2                       468.392857           584.454545       1310.462428   \n",
      "3                       785.742857          1165.943463       2109.431851   \n",
      "4                      2353.519005          2527.268790       3075.771459   \n",
      "\n",
      "   sending_internet_unknown  sending_marriage_unknown  sending_married  ...  \\\n",
      "0                347.698113                576.362069      1921.620722  ...   \n",
      "1                459.166667                342.800000      1383.286109  ...   \n",
      "2                514.312500               3800.000000      1079.759162  ...   \n",
      "3               1043.500000                549.695652      1945.953046  ...   \n",
      "4               1941.578834                650.206897      3749.195659  ...   \n",
      "\n",
      "   sending_unknown_employment_status  sending_unknown_indigeneity  \\\n",
      "0                        1218.357143                   840.339623   \n",
      "1                         535.750000                   576.379310   \n",
      "2                         540.000000                   629.215385   \n",
      "3                         771.400000                   694.579439   \n",
      "4                        1531.622086                  2064.311411   \n",
      "\n",
      "   sending_unpaid_worker  sending_urban  sending_weighted_avg_income  \\\n",
      "0                      0    1597.239059                  1124.200953   \n",
      "1                      0      -1.000000                   908.782316   \n",
      "2                      0      -1.000000                   628.585520   \n",
      "3                      0    1436.934837                  1173.751889   \n",
      "4                      0    2319.113608                  2230.022635   \n",
      "\n",
      "   sending_weighted_avg_income_abroad  sending_weighted_avg_no_income_abroad  \\\n",
      "0                          768.788518                            1213.505104   \n",
      "1                          720.767123                             929.317603   \n",
      "2                          486.116034                             738.533015   \n",
      "3                          861.385645                            1219.547797   \n",
      "4                         1672.340116                            2273.630651   \n",
      "\n",
      "   sending_weighted_avg_unknown_income_abroad  sending_widowed  US_MIG_05_10  \n",
      "0                                 1931.825000       460.430041           961  \n",
      "1                                  845.567568       745.377359           154  \n",
      "2                                   -1.000000       276.569767           905  \n",
      "3                                 1643.137255       741.363985           225  \n",
      "4                                 3946.180995      1241.236982          1071  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "####### Load our Data\n",
    "#y - 'number_moved'\n",
    "#x - 'everything else that is or can be represented as a float.'\n",
    "devSet = pd.read_csv(\"./us_migration.csv\")\n",
    "devSet = devSet.loc[:, ~devSet.columns.str.contains('^Unnamed')]\n",
    "devSet = devSet.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "devSet = devSet.dropna(axis=1)\n",
    "devSet = devSet.drop(['sending'], axis = 1)\n",
    "\n",
    "print(devSet.head())\n",
    "\n",
    "y = torch.Tensor(devSet['US_MIG_05_10'].values)\n",
    "X = devSet.loc[:, devSet.columns != \"US_MIG_05_10\"].values\n",
    "\n",
    "mMScale = preprocessing.MinMaxScaler()\n",
    "X = mMScale.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, split):\n",
    "\n",
    "    train_num = int(len(X) * split)\n",
    "    val_num = int(len(X) - train_num)\n",
    "\n",
    "    train_indices = random.sample(range(len(X)), train_num)\n",
    "    val_indices = [i for i in range(len(X)) if i not in train_indices]\n",
    "\n",
    "    x_train, x_val = X[train_indices], X[val_indices]\n",
    "    y_train, y_val = y[val_indices], y[val_indices]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Build and fit the Model\n",
    "lr = 1e-6\n",
    "batchSize = 50\n",
    "model = socialSig.SocialSigNet(X=X, outDim = batchSize)\n",
    "epochs = 1\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = train_test_split(X, y, .80)\n",
    "\n",
    "train = [(k,v) for k,v in zip(x_train, y_train)]\n",
    "val = [(k,v) for k,v in zip(x_val, y_val)]\n",
    "\n",
    "train = torch.utils.data.DataLoader(train, batch_size = batchSize, shuffle = True)\n",
    "val = torch.utils.data.DataLoader(val, batch_size = batchSize, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1750, 0.0627, 0.1885,  ..., 0.1726, 0.1140, 0.1119],\n",
      "        [0.0618, 0.0012, 0.1161,  ..., 0.0564, 0.0093, 0.0778],\n",
      "        [0.3315, 0.0000, 0.3878,  ..., 0.3056, 0.0834, 0.4247],\n",
      "        ...,\n",
      "        [0.2739, 0.0308, 0.2569,  ..., 0.2696, 0.1155, 0.2711],\n",
      "        [0.2552, 0.1112, 0.2368,  ..., 0.2534, 0.0486, 0.1823],\n",
      "        [0.1958, 0.0588, 0.2346,  ..., 0.1934, 0.1110, 0.1771]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.1453, 0.0508, 0.1799,  ..., 0.1416, 0.0445, 0.1072],\n",
      "        [0.0908, 0.0740, 0.1275,  ..., 0.0891, 0.0455, 0.0494],\n",
      "        [0.1359, 0.0618, 0.1424,  ..., 0.1330, 0.1522, 0.1133],\n",
      "        ...,\n",
      "        [0.0311, 0.0017, 0.1044,  ..., 0.0298, 0.0286, 0.0415],\n",
      "        [0.1355, 0.0715, 0.1548,  ..., 0.1365, 0.0509, 0.0523],\n",
      "        [0.1938, 0.0988, 0.2327,  ..., 0.1898, 0.0829, 0.1073]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.1775, 0.0901, 0.2068,  ..., 0.1699, 0.5305, 0.1723],\n",
      "        [0.2378, 0.0747, 0.2506,  ..., 0.2350, 0.1423, 0.2397],\n",
      "        [0.1770, 0.0917, 0.1794,  ..., 0.1768, 0.0608, 0.1293],\n",
      "        ...,\n",
      "        [0.1685, 0.1144, 0.1768,  ..., 0.1645, 0.0794, 0.0794],\n",
      "        [0.0468, 0.0000, 0.0600,  ..., 0.0487, 0.0000, 0.1366],\n",
      "        [0.0151, 0.0000, 0.0334,  ..., 0.0141, 0.0068, 0.0008]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0414, 0.0000, 0.1419,  ..., 0.0378, 0.0000, 0.0555],\n",
      "        [0.0617, 0.0028, 0.1211,  ..., 0.0595, 0.0195, 0.0707],\n",
      "        [0.2363, 0.0826, 0.3357,  ..., 0.2312, 0.0949, 0.2649],\n",
      "        ...,\n",
      "        [0.3346, 0.1314, 0.3261,  ..., 0.3287, 0.1911, 0.2439],\n",
      "        [0.0877, 0.0215, 0.0973,  ..., 0.0839, 0.1584, 0.0375],\n",
      "        [0.2741, 0.0602, 0.2884,  ..., 0.2756, 0.0894, 0.2088]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.1007, 0.0501, 0.1085,  ..., 0.1042, 0.0000, 0.0542],\n",
      "        [0.1817, 0.0581, 0.2168,  ..., 0.1783, 0.0801, 0.1717],\n",
      "        [0.1462, 0.0334, 0.1920,  ..., 0.1486, 0.0000, 0.0895],\n",
      "        ...,\n",
      "        [0.0321, 0.0048, 0.0583,  ..., 0.0315, 0.0070, 0.0274],\n",
      "        [0.1078, 0.0064, 0.1026,  ..., 0.1093, 0.0587, 0.0707],\n",
      "        [0.1682, 0.0174, 0.2035,  ..., 0.1639, 0.0501, 0.1076]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[3.6427e-01, 6.6729e-02, 2.5913e-02,  ..., 3.8134e-01, 0.0000e+00,\n",
      "         3.7421e-02],\n",
      "        [7.2241e-02, 0.0000e+00, 4.6009e-02,  ..., 7.2949e-02, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.6101e-01, 8.8824e-02, 1.6407e-01,  ..., 1.5749e-01, 1.7780e-01,\n",
      "         1.4226e-01],\n",
      "        ...,\n",
      "        [1.1936e-01, 2.7856e-02, 1.7099e-01,  ..., 1.1823e-01, 2.3419e-02,\n",
      "         9.0045e-02],\n",
      "        [1.5790e-02, 7.7773e-05, 1.1542e-01,  ..., 1.5417e-02, 1.5544e-03,\n",
      "         2.6438e-03],\n",
      "        [2.5480e-01, 4.9811e-02, 2.6567e-01,  ..., 2.4955e-01, 1.3390e-01,\n",
      "         2.6851e-01]], dtype=torch.float64)\n",
      "tensor([[2.2750e-01, 8.5095e-02, 2.1649e-01,  ..., 2.2173e-01, 1.6072e-01,\n",
      "         3.3391e-01],\n",
      "        [1.3586e-02, 0.0000e+00, 6.1352e-02,  ..., 1.1845e-02, 6.1891e-02,\n",
      "         1.8120e-03],\n",
      "        [2.0120e-01, 7.3279e-03, 2.2250e-01,  ..., 2.0511e-01, 5.2978e-02,\n",
      "         1.5091e-01],\n",
      "        ...,\n",
      "        [2.3660e-01, 1.2744e-01, 2.6909e-01,  ..., 2.3398e-01, 4.2283e-02,\n",
      "         1.7939e-01],\n",
      "        [1.2557e-01, 4.0263e-02, 1.2128e-01,  ..., 1.2062e-01, 2.1589e-02,\n",
      "         1.3097e-01],\n",
      "        [3.0705e-02, 2.8359e-02, 3.1602e-02,  ..., 2.7909e-02, 6.8006e-05,\n",
      "         1.3194e-02]], dtype=torch.float64)\n",
      "tensor([[9.6603e-02, 0.0000e+00, 1.3220e-01,  ..., 9.4485e-02, 2.3833e-02,\n",
      "         8.9829e-02],\n",
      "        [2.1907e-01, 8.4283e-02, 2.4746e-01,  ..., 2.1826e-01, 1.6978e-01,\n",
      "         1.8015e-01],\n",
      "        [1.2647e-01, 5.1427e-02, 1.3035e-01,  ..., 1.2278e-01, 1.7202e-01,\n",
      "         1.2816e-01],\n",
      "        ...,\n",
      "        [3.5550e-02, 0.0000e+00, 1.3285e-01,  ..., 3.5110e-02, 3.2454e-02,\n",
      "         2.0936e-04],\n",
      "        [4.9442e-02, 0.0000e+00, 1.3201e-01,  ..., 4.7639e-02, 2.5330e-02,\n",
      "         4.3024e-02],\n",
      "        [2.4662e-01, 5.7412e-02, 2.1031e-01,  ..., 2.3563e-01, 1.6805e-01,\n",
      "         2.4349e-01]], dtype=torch.float64)\n",
      "tensor([[5.2683e-02, 0.0000e+00, 3.0274e-02,  ..., 4.8088e-02, 0.0000e+00,\n",
      "         2.7784e-02],\n",
      "        [2.0275e-01, 2.5060e-01, 2.7168e-01,  ..., 2.2755e-01, 1.1651e-01,\n",
      "         1.5621e-01],\n",
      "        [2.0670e-01, 4.1959e-02, 2.1818e-01,  ..., 2.0069e-01, 1.2420e-01,\n",
      "         2.1116e-01],\n",
      "        ...,\n",
      "        [6.8259e-02, 5.4407e-03, 9.0797e-02,  ..., 7.0740e-02, 2.3240e-02,\n",
      "         5.0684e-02],\n",
      "        [5.9893e-02, 7.7773e-05, 5.4079e-02,  ..., 5.7979e-02, 4.3203e-02,\n",
      "         6.5459e-02],\n",
      "        [6.0660e-02, 0.0000e+00, 5.9056e-02,  ..., 6.7844e-02, 9.7831e-03,\n",
      "         2.2308e-02]], dtype=torch.float64)\n",
      "tensor([[1.4824e-02, 0.0000e+00, 2.3491e-02, 1.4011e-02, 0.0000e+00, 1.0358e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3795e-02, 0.0000e+00, 1.9173e-02,\n",
      "         0.0000e+00, 2.7894e-03, 2.5266e-01, 1.6346e-02, 0.0000e+00, 1.6475e-02,\n",
      "         3.6190e-04, 8.3959e-04, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         1.4675e-02, 7.5954e-03, 1.4964e-02, 6.8006e-05, 1.1683e-02],\n",
      "        [2.2460e-01, 3.1695e-02, 2.4232e-01, 2.1312e-01, 1.9080e-02, 1.5726e-01,\n",
      "         1.1450e-01, 3.8859e-02, 6.6363e-03, 2.1513e-01, 2.2057e-01, 2.4979e-01,\n",
      "         1.5277e-03, 3.2346e-02, 2.6025e-01, 9.6909e-02, 2.5492e-01, 1.6717e-01,\n",
      "         1.6859e-02, 1.1224e-02, 1.3376e-01, 5.7517e-02, 1.0000e+00, 1.0679e-01,\n",
      "         2.2102e-01, 1.4726e-01, 2.2100e-01, 1.7045e-01, 2.2097e-01],\n",
      "        [1.6932e-01, 1.2842e-02, 1.6015e-01, 1.6827e-01, 1.7499e-02, 1.1123e-01,\n",
      "         9.2188e-02, 3.8796e-02, 1.4880e-01, 1.5477e-01, 1.6665e-01, 1.9527e-01,\n",
      "         0.0000e+00, 3.1273e-02, 2.1063e-01, 6.4751e-02, 1.5442e-01, 1.3611e-01,\n",
      "         8.1119e-03, 3.6955e-03, 9.1805e-02, 5.8208e-02, 1.0000e+00, 7.6620e-02,\n",
      "         1.6695e-01, 1.4664e-01, 1.6454e-01, 8.3763e-02, 1.9103e-01],\n",
      "        [1.7026e-02, 0.0000e+00, 7.5301e-02, 1.5072e-02, 1.1325e-03, 1.1483e-02,\n",
      "         5.2523e-02, 3.3332e-05, 0.0000e+00, 2.0048e-02, 5.2399e-02, 2.0914e-02,\n",
      "         0.0000e+00, 1.3345e-03, 1.7590e-01, 6.7450e-03, 2.8769e-02, 1.1512e-02,\n",
      "         1.6071e-03, 9.0770e-03, 2.8273e-02, 8.7365e-03, 1.0000e+00, 3.0292e-02,\n",
      "         1.6845e-02, 7.8308e-02, 1.6375e-02, 1.3323e-02, 1.3301e-02],\n",
      "        [1.4757e-01, 2.9619e-02, 1.8831e-01, 1.3597e-01, 1.3158e-02, 1.5315e-01,\n",
      "         9.5036e-02, 1.9033e-02, 1.4159e-02, 1.4779e-01, 1.4245e-01, 1.6953e-01,\n",
      "         3.2608e-03, 2.4761e-02, 2.2909e-01, 7.5478e-02, 1.8990e-01, 1.0840e-01,\n",
      "         1.1978e-02, 8.8388e-03, 1.7569e-01, 3.2845e-02, 1.0000e+00, 8.4717e-02,\n",
      "         1.4571e-01, 1.2105e-01, 1.4526e-01, 4.4698e-02, 7.9736e-02],\n",
      "        [2.5616e-02, 0.0000e+00, 9.3937e-02, 2.0410e-02, 0.0000e+00, 2.4636e-02,\n",
      "         6.4149e-02, 0.0000e+00, 0.0000e+00, 2.4316e-02, 1.0105e-02, 3.2490e-02,\n",
      "         0.0000e+00, 4.8093e-03, 1.9575e-01, 3.7959e-02, 0.0000e+00, 2.7082e-02,\n",
      "         4.2375e-04, 5.5859e-04, 1.5007e-01, 8.5153e-04, 1.0000e+00, 0.0000e+00,\n",
      "         2.5302e-02, 1.8673e-02, 2.5224e-02, 0.0000e+00, 1.2377e-02],\n",
      "        [2.0928e-01, 8.8960e-02, 2.5316e-01, 1.8647e-01, 3.9951e-02, 1.5191e-01,\n",
      "         1.2273e-01, 5.3665e-03, 8.7651e-02, 1.9186e-01, 2.0394e-01, 2.2534e-01,\n",
      "         2.9002e-04, 2.3692e-02, 2.4327e-01, 1.0872e-01, 1.9342e-01, 1.9657e-01,\n",
      "         1.1594e-02, 4.9469e-03, 1.3991e-01, 5.2430e-02, 1.0000e+00, 1.1403e-01,\n",
      "         2.0596e-01, 1.6106e-01, 2.0766e-01, 7.2434e-02, 1.0019e-01],\n",
      "        [1.2449e-02, 7.7773e-05, 3.3548e-02, 1.0916e-02, 1.2606e-03, 8.5239e-03,\n",
      "         2.1860e-02, 3.3332e-05, 4.0056e-02, 1.5207e-02, 5.3365e-02, 1.5856e-02,\n",
      "         0.0000e+00, 1.2883e-03, 2.1185e-01, 1.7987e-02, 1.6608e-02, 7.8423e-03,\n",
      "         2.5897e-03, 7.2347e-03, 5.9096e-03, 4.1302e-05, 1.0000e+00, 1.6981e-02,\n",
      "         1.2290e-02, 1.3504e-02, 1.1894e-02, 4.0096e-03, 4.8157e-03],\n",
      "        [2.3072e-01, 1.6977e-01, 2.9653e-01, 1.9117e-01, 2.6469e-02, 1.7799e-01,\n",
      "         8.3097e-02, 7.5747e-02, 0.0000e+00, 2.1819e-01, 2.0492e-01, 2.9327e-01,\n",
      "         0.0000e+00, 4.6943e-02, 2.3129e-01, 9.6120e-02, 2.6794e-01, 1.8092e-01,\n",
      "         7.9601e-03, 1.7471e-03, 7.0453e-02, 1.1628e-01, 1.0000e+00, 1.0257e-01,\n",
      "         2.2823e-01, 2.0006e-01, 2.2455e-01, 2.5753e-01, 3.1375e-01],\n",
      "        [2.3781e-01, 1.4529e-01, 2.6367e-01, 2.2453e-01, 2.1455e-02, 1.7751e-01,\n",
      "         1.0618e-01, 5.4212e-02, 4.0723e-02, 2.3972e-01, 2.3292e-01, 2.8297e-01,\n",
      "         0.0000e+00, 4.4083e-02, 2.9035e-01, 1.0650e-01, 2.4629e-01, 1.5663e-01,\n",
      "         1.5753e-02, 1.0088e-02, 1.3979e-01, 5.4911e-02, 1.0000e+00, 1.0850e-01,\n",
      "         2.3514e-01, 1.8484e-01, 2.3319e-01, 9.9900e-02, 1.6668e-01],\n",
      "        [9.8630e-02, 7.8060e-02, 1.0351e-01, 9.4688e-02, 1.1893e-02, 6.0702e-02,\n",
      "         8.5408e-02, 2.5807e-02, 1.4032e-01, 1.0456e-01, 1.5568e-01, 1.1361e-01,\n",
      "         0.0000e+00, 1.3861e-02, 1.7077e-01, 5.4900e-02, 1.2883e-01, 6.2779e-02,\n",
      "         6.3008e-03, 5.3693e-03, 5.1456e-02, 3.5791e-02, 1.0000e+00, 5.5738e-02,\n",
      "         9.7808e-02, 1.3366e-01, 9.5605e-02, 5.0299e-02, 1.0601e-01],\n",
      "        [3.6834e-02, 0.0000e+00, 1.6381e-02, 4.3009e-02, 0.0000e+00, 2.5768e-02,\n",
      "         1.1970e-01, 0.0000e+00, 0.0000e+00, 3.6103e-02, 3.2798e-02, 4.0496e-02,\n",
      "         0.0000e+00, 6.8623e-03, 1.2098e-01, 3.6672e-02, 2.6392e-02, 1.9456e-02,\n",
      "         7.7353e-05, 5.8779e-05, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         3.6103e-02, 3.9003e-02, 3.4296e-02, 0.0000e+00, 2.0936e-04],\n",
      "        [1.3903e-01, 4.3630e-02, 2.5665e-01, 1.0913e-01, 1.3215e-02, 3.3426e-02,\n",
      "         1.4546e-01, 1.4848e-02, 0.0000e+00, 1.5555e-01, 2.8526e-01, 1.4378e-01,\n",
      "         0.0000e+00, 2.6046e-02, 3.6885e-01, 7.8115e-02, 1.5225e-01, 8.6451e-02,\n",
      "         3.4327e-03, 1.3807e-03, 2.1667e-01, 8.5994e-02, 1.0000e+00, 0.0000e+00,\n",
      "         1.3703e-01, 1.3060e-01, 1.3459e-01, 0.0000e+00, 1.9720e-01],\n",
      "        [1.0895e-01, 8.1629e-02, 1.1892e-01, 1.0523e-01, 9.2355e-03, 7.6359e-02,\n",
      "         9.1239e-02, 0.0000e+00, 4.4266e-02, 1.0544e-01, 1.0851e-01, 1.3477e-01,\n",
      "         3.4548e-02, 1.8315e-02, 2.2766e-01, 5.4448e-02, 1.5273e-01, 9.7086e-02,\n",
      "         6.0097e-03, 3.6079e-03, 5.8573e-02, 3.6738e-02, 1.0000e+00, 7.7081e-02,\n",
      "         1.0957e-01, 1.0943e-01, 1.0575e-01, 5.3290e-02, 6.6884e-02],\n",
      "        [5.9369e-02, 5.5633e-02, 7.3706e-02, 5.4949e-02, 6.9020e-03, 4.1761e-02,\n",
      "         1.2052e-01, 2.7923e-02, 9.1619e-05, 5.2855e-02, 5.2884e-02, 7.2551e-02,\n",
      "         0.0000e+00, 1.1199e-02, 1.5658e-01, 2.6783e-02, 4.7623e-02, 6.0692e-02,\n",
      "         1.1332e-03, 6.4164e-04, 0.0000e+00, 1.9566e-02, 1.0000e+00, 0.0000e+00,\n",
      "         5.8920e-02, 3.6628e-02, 6.0933e-02, 6.8006e-05, 2.7853e-02]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for inputs, output in train:\n",
    "    print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/heatherbaier/Desktop/CAOE/sig/socialSig.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(\"    W at beginning: \", torch.tensor(self.W))\n",
      "/Users/heatherbaier/Desktop/CAOE/sig/socialSig.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  taken = torch.take(batchX, construct_noOverlap_indices(torch.tensor(self.W, dtype = torch.float32), batchX.shape[0], self.W.shape[0]))\n",
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/torch/nn/functional.py:3455: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "    W at beginning:  tensor([2.1385e-02, 9.4206e-03, 9.6362e-02, 5.3210e-02, 1.4519e-05, 4.7531e-02,\n",
      "        8.8082e-02, 3.7379e-02, 8.0122e-02, 6.7977e-02, 6.6265e-03, 3.3945e-02,\n",
      "        6.7518e-02, 6.7380e-02, 5.9933e-02, 2.2598e-02, 7.0929e-02, 1.1315e-02,\n",
      "        7.4608e-02, 8.8387e-02, 4.0019e-02, 9.5174e-02, 6.5706e-02, 3.0055e-02,\n",
      "        5.6044e-02, 3.6465e-02, 7.0851e-02, 6.7270e-02, 8.3068e-02])\n",
      "    W at beginning:  tensor([2.1305e-02, 9.4286e-03, 9.6977e-02, 5.4738e-02, 1.7783e-05, 4.7232e-02,\n",
      "        8.8646e-02, 3.7940e-02, 8.0588e-02, 6.7504e-02, 6.7540e-03, 3.3867e-02,\n",
      "        6.7427e-02, 6.7903e-02, 6.0355e-02, 2.2637e-02, 6.9931e-02, 1.1264e-02,\n",
      "        7.4695e-02, 8.8060e-02, 4.0224e-02, 9.5238e-02, 6.5812e-02, 2.9787e-02,\n",
      "        5.6330e-02, 3.6731e-02, 7.1019e-02, 6.6993e-02, 8.2748e-02])\n",
      "    W at beginning:  tensor([0.0216, 0.0102, 0.0981, 0.0560, 0.0019, 0.0474, 0.0877, 0.0407, 0.0828,\n",
      "        0.0697, 0.0086, 0.0349, 0.0689, 0.0705, 0.0572, 0.0095, 0.0693, 0.0109,\n",
      "        0.0757, 0.0845, 0.0388, 0.0969, 0.0673, 0.0299, 0.0563, 0.0360, 0.0783,\n",
      "        0.0685, 0.0835])\n",
      "    W at beginning:  tensor([ 0.0133, -0.0274,  0.0351,  0.0858,  0.0067,  0.0536,  0.0031,  0.1435,\n",
      "         0.0078,  0.0901,  0.0261,  0.0372,  0.0571,  0.2707,  0.1183,  0.0093,\n",
      "         0.0814,  0.0175,  0.0060,  0.0457,  0.0129,  0.0966,  0.0487,  0.0291,\n",
      "         0.0336,  0.0381,  0.0632,  0.0694,  0.0691])\n",
      "    W at beginning:  tensor([ 0.0149, -0.0264,  0.0383,  0.0910,  0.0096,  0.0545,  0.0045,  0.1436,\n",
      "         0.0112,  0.0941,  0.0245,  0.0367,  0.0577,  0.2694,  0.1264,  0.0181,\n",
      "         0.0827,  0.0185,  0.0084,  0.0462,  0.0170,  0.1037,  0.0454,  0.0271,\n",
      "         0.0348,  0.0390,  0.0634,  0.0648,  0.0572])\n",
      "    W at beginning:  tensor([ 0.0119, -0.0284,  0.0336,  0.0882,  0.0080,  0.0553,  0.0029,  0.1432,\n",
      "         0.0123,  0.0991,  0.0362,  0.0397,  0.0587,  0.2684,  0.1371,  0.0147,\n",
      "         0.0793,  0.0211,  0.0075,  0.0447,  0.0214,  0.1233,  0.0558,  0.0280,\n",
      "         0.0344,  0.0353,  0.0625,  0.0673,  0.0526])\n",
      "    W at beginning:  tensor([ 1.1235e-02, -2.9630e-02,  3.1480e-02,  8.7979e-02,  7.9155e-03,\n",
      "         5.5984e-02, -9.6700e-05,  1.4613e-01,  1.1534e-02,  9.9155e-02,\n",
      "         3.3357e-02,  3.7526e-02,  5.8076e-02,  2.7287e-01,  1.3960e-01,\n",
      "         1.6952e-02,  7.8866e-02,  2.2443e-02,  9.0616e-03,  4.2746e-02,\n",
      "         2.0933e-02,  1.2510e-01,  5.5445e-02,  2.7335e-02,  3.5099e-02,\n",
      "         3.4919e-02,  6.2386e-02,  6.7636e-02,  5.3532e-02])\n",
      "    W at beginning:  tensor([ 0.0060, -0.0247,  0.0212,  0.0901,  0.0084,  0.0724, -0.0204,  0.1327,\n",
      "         0.0251,  0.0973,  0.0161,  0.0520,  0.0424,  0.3010,  0.1730,  0.0251,\n",
      "         0.0704,  0.0504,  0.0027,  0.0399,  0.0219,  0.1170,  0.0118,  0.0112,\n",
      "         0.0348,  0.0390,  0.0593,  0.0681,  0.0550])\n",
      "    W at beginning:  tensor([ 0.0088, -0.0266,  0.0206,  0.0899,  0.0085,  0.0724,  0.0033,  0.1300,\n",
      "         0.0220,  0.0961,  0.0160,  0.0519,  0.0488,  0.2994,  0.1710,  0.0211,\n",
      "         0.0696,  0.0502,  0.0022,  0.0384,  0.0152,  0.1134,  0.0114,  0.0110,\n",
      "         0.0347,  0.0392,  0.0578,  0.0651,  0.0549])\n",
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/ipykernel_launcher.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "Epoch:  0\n",
      "  Train:\n",
      "    Loss:  9838980.6\n",
      "    MAE:  239.91559906005858\n",
      "  Val:\n",
      "    Loss:  9814683.45\n",
      "    MAE:  217.92244720458984\n"
     ]
    }
   ],
   "source": [
    "best_mae = 9000000000000000000\n",
    "best_model_wts = deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    for phase in ['train','val']:\n",
    "\n",
    "\n",
    "\n",
    "        if phase == 'train':\n",
    "\n",
    "            c = 1\n",
    "            running_train_mae, running_train_loss = 0, 0\n",
    "\n",
    "            # print(\"In training\")\n",
    "\n",
    "            for inputs, output in train:\n",
    "\n",
    "                if len(inputs) == batchSize:\n",
    "\n",
    "                    # print(c)\n",
    "                    c += 1\n",
    "\n",
    "                    inputs = torch.tensor(inputs, dtype = torch.float32, requires_grad = True)\n",
    "                    output = torch.reshape(torch.tensor(output, dtype = torch.float32, requires_grad = True), (batchSize,1))\n",
    "\n",
    "                    # Forward pass\n",
    "                    y_pred = model(inputs, str(epoch) + str(c))\n",
    "                    loss = criterion(y_pred, output)  \n",
    "                    \n",
    "                    # Zero gradients, perform a backward pass, and update the weights.\n",
    "                    optimizer.zero_grad()\n",
    "                    grad = torch.autograd.grad(outputs = loss, inputs = inputs, retain_graph = True)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Update the coordinate weights\n",
    "                    # https://discuss.pytorch.org/t/updatation-of-parameters-without-using-optimizer-step/34244/4\n",
    "                    with torch.no_grad():\n",
    "                        for name, p in model.named_parameters():\n",
    "                            if name == 'SocialSig.W':\n",
    "                                new_val = update_function(p, grad[0], loss, lr)\n",
    "                                p.copy_(new_val)\n",
    "\n",
    "                    running_train_mae += mae(y_pred, output).item()\n",
    "                    running_train_loss += loss.item()\n",
    "\n",
    "        if phase == 'val':\n",
    "\n",
    "            c = 1\n",
    "            running_val_mae, running_val_loss,  = 0, 0\n",
    "\n",
    "            # print(\"In validation\")\n",
    "\n",
    "            for inputs, output in val:\n",
    "\n",
    "                if len(inputs) == batchSize:\n",
    "\n",
    "                    # print(c)\n",
    "                    c += 1\n",
    "\n",
    "                    inputs = torch.tensor(inputs, dtype = torch.float32, requires_grad = True)\n",
    "                    output = torch.reshape(torch.tensor(output, dtype = torch.float32, requires_grad = True), (batchSize,1))\n",
    "\n",
    "                    # Forward pass\n",
    "                    y_pred = model(inputs, 1)\n",
    "                    loss = criterion(y_pred, output)  \n",
    "\n",
    "                    running_val_mae += mae(y_pred, output).item()\n",
    "                    running_val_loss += loss.item()\n",
    "                    \n",
    "                    if mae(y_pred, output).item() < best_mae:\n",
    "                        best_mae = mae(y_pred, output).item()\n",
    "                        best_model_wts = deepcopy(model.state_dict())\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "    print(\"Epoch: \", epoch)  \n",
    "    print(\"  Train:\")\n",
    "    print(\"    Loss: \", running_train_loss / c)      \n",
    "    print(\"    MAE: \", running_train_mae / c)\n",
    "    print(\"  Val:\")\n",
    "    print(\"    Loss: \", running_val_loss / c)      \n",
    "    print(\"    MAE: \", running_val_mae / c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15086376, 0.01904088, 0.17205208, ..., 0.15731832, 0.13144279,\n",
       "        0.09660652],\n",
       "       [0.12192231, 0.04674133, 0.18605187, ..., 0.1205067 , 0.05757128,\n",
       "        0.15626403],\n",
       "       [0.08485822, 0.04340877, 0.10657675, ..., 0.09579383, 0.        ,\n",
       "        0.05811292],\n",
       "       ...,\n",
       "       [0.2560983 , 0.06107871, 0.22930659, ..., 0.24920383, 0.04052688,\n",
       "        0.29325165],\n",
       "       [0.30418829, 0.12659953, 0.30113786, ..., 0.29673268, 0.09956838,\n",
       "        0.2626708 ],\n",
       "       [0.45947368, 0.26082901, 0.4582634 , ..., 0.44939452, 0.22173665,\n",
       "        0.33150409]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "tensor([[169.2038]], grad_fn=<AddmmBackward>)\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "tensor([[156.2059]], grad_fn=<AddmmBackward>)\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "tensor([[163.5242]], grad_fn=<AddmmBackward>)\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "tensor([[166.0314]], grad_fn=<AddmmBackward>)\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "tensor([[177.9655]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "\n",
    "    imput = torch.reshape(torch.tensor(X[i], dtype = torch.float32), (1,1,29))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    print(model(imput, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7388e-01, 3.0840e-02, 2.5688e-01, 2.7936e-01, 3.6218e-02, 1.8417e-01,\n",
       "         1.2314e-01, 0.0000e+00, 0.0000e+00, 2.4442e-01, 2.6865e-01, 2.7435e-01,\n",
       "         0.0000e+00, 3.8383e-02, 2.8620e-01, 1.0488e-01, 2.7305e-01, 2.4308e-01,\n",
       "         1.2009e-02, 4.6390e-03, 2.4740e-01, 1.1830e-01, 1.0000e+00, 1.2805e-01,\n",
       "         2.7101e-01, 1.9818e-01, 2.6964e-01, 1.1546e-01, 2.7110e-01],\n",
       "        [3.8522e-02, 1.3040e-02, 4.8051e-02, 3.5860e-02, 6.5743e-03, 2.6583e-02,\n",
       "         5.7025e-02, 0.0000e+00, 5.1311e-02, 4.7917e-02, 5.6560e-02, 4.9159e-02,\n",
       "         0.0000e+00, 4.6879e-03, 1.3266e-01, 1.8648e-02, 6.1607e-02, 2.2079e-02,\n",
       "         1.7460e-03, 2.3633e-03, 1.0237e-01, 5.4286e-03, 1.0000e+00, 2.7162e-02,\n",
       "         3.8032e-02, 2.5502e-02, 3.7844e-02, 1.7950e-02, 4.9828e-02],\n",
       "        [3.4198e-02, 0.0000e+00, 3.1788e-02, 3.2782e-02, 2.3091e-03, 2.3490e-02,\n",
       "         0.0000e+00, 3.3332e-05, 9.1619e-05, 3.4928e-02, 8.4081e-02, 4.4449e-02,\n",
       "         0.0000e+00, 4.3339e-03, 1.8147e-01, 2.0360e-02, 3.8448e-02, 2.2578e-02,\n",
       "         8.4638e-04, 1.5609e-03, 2.5642e-01, 5.0979e-03, 1.0000e+00, 1.9591e-02,\n",
       "         3.3844e-02, 3.8449e-02, 3.3383e-02, 5.0139e-03, 7.6865e-03],\n",
       "        [2.3281e-02, 0.0000e+00, 3.9995e-02, 2.1494e-02, 0.0000e+00, 1.7799e-02,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3106e-02, 1.3961e-02, 2.9961e-02,\n",
       "         0.0000e+00, 4.3782e-03, 2.3512e-01, 8.6578e-03, 9.5833e-02, 2.1071e-02,\n",
       "         2.6487e-04, 3.7922e-04, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "         2.3034e-02, 0.0000e+00, 2.2883e-02, 0.0000e+00, 1.2998e-03],\n",
       "        [2.0921e-01, 4.4923e-02, 2.1290e-01, 2.0195e-01, 1.9600e-02, 1.3742e-01,\n",
       "         1.1288e-01, 3.7611e-02, 5.5524e-02, 1.9996e-01, 2.0788e-01, 2.4176e-01,\n",
       "         0.0000e+00, 3.9808e-02, 2.4944e-01, 7.7954e-02, 1.9615e-01, 1.4628e-01,\n",
       "         1.2730e-02, 7.3144e-03, 2.1051e-01, 6.9689e-02, 1.0000e+00, 9.3800e-02,\n",
       "         2.0665e-01, 1.6759e-01, 2.0395e-01, 1.0343e-01, 1.9592e-01],\n",
       "        [2.4739e-01, 2.0309e-01, 2.5168e-01, 2.4516e-01, 4.0134e-02, 1.6648e-01,\n",
       "         1.0699e-01, 7.5307e-02, 5.8991e-02, 2.4289e-01, 2.4459e-01, 2.6559e-01,\n",
       "         0.0000e+00, 3.3407e-02, 2.6680e-01, 1.2044e-01, 2.2077e-01, 1.9168e-01,\n",
       "         1.1707e-02, 4.6583e-03, 6.6981e-02, 6.3210e-02, 1.0000e+00, 1.1580e-01,\n",
       "         2.4463e-01, 1.5016e-01, 2.5228e-01, 1.3563e-01, 1.0917e-01],\n",
       "        [2.9384e-02, 0.0000e+00, 2.6786e-02, 2.7921e-02, 4.0031e-03, 2.0296e-02,\n",
       "         6.4615e-02, 1.1460e-02, 5.5063e-02, 3.1986e-02, 1.9470e-02, 3.6692e-02,\n",
       "         0.0000e+00, 5.5223e-03, 1.0022e-01, 1.0607e-02, 2.0487e-02, 2.3229e-02,\n",
       "         1.1723e-03, 1.3652e-03, 1.9359e-02, 4.1163e-02, 1.0000e+00, 0.0000e+00,\n",
       "         2.9053e-02, 4.1366e-02, 2.8200e-02, 1.8936e-02, 3.0097e-02],\n",
       "        [1.6058e-01, 9.0202e-02, 1.8378e-01, 1.4656e-01, 4.1085e-02, 1.4942e-01,\n",
       "         1.0090e-01, 8.2279e-02, 0.0000e+00, 1.4465e-01, 1.5312e-01, 1.7268e-01,\n",
       "         1.3833e-03, 2.1833e-02, 1.9427e-01, 7.2510e-02, 1.7541e-01, 1.3406e-01,\n",
       "         8.2984e-03, 3.8347e-03, 3.9307e-01, 7.0554e-02, 1.0000e+00, 8.6764e-02,\n",
       "         1.5788e-01, 1.0030e-01, 1.6472e-01, 4.2191e-02, 1.0984e-01],\n",
       "        [2.0365e-01, 7.3052e-02, 2.4116e-01, 1.8855e-01, 2.5637e-02, 1.2851e-01,\n",
       "         1.1005e-01, 3.9958e-02, 5.6121e-02, 1.9319e-01, 2.0747e-01, 2.1467e-01,\n",
       "         1.1736e-02, 3.1751e-02, 2.3047e-01, 8.2616e-02, 2.6615e-01, 1.5826e-01,\n",
       "         5.1630e-02, 2.3659e-02, 1.1326e-01, 6.0390e-02, 1.0000e+00, 9.3823e-02,\n",
       "         2.0145e-01, 1.6961e-01, 1.9888e-01, 8.0093e-02, 1.5139e-01],\n",
       "        [1.6970e-01, 7.4904e-02, 1.8935e-01, 1.5941e-01, 1.8124e-02, 1.2285e-01,\n",
       "         9.8598e-02, 0.0000e+00, 4.7712e-02, 1.6891e-01, 1.6594e-01, 1.9633e-01,\n",
       "         4.3706e-03, 2.5716e-02, 2.2867e-01, 8.4214e-02, 1.2098e-01, 1.2501e-01,\n",
       "         1.1106e-02, 7.0428e-03, 0.0000e+00, 4.4021e-02, 1.0000e+00, 9.3105e-02,\n",
       "         1.6759e-01, 8.1891e-02, 1.7020e-01, 1.0937e-01, 1.4608e-01],\n",
       "        [8.4331e-02, 6.3937e-03, 9.7737e-02, 7.9306e-02, 7.2285e-03, 5.8668e-02,\n",
       "         8.1548e-02, 2.1618e-02, 7.4491e-02, 7.5026e-02, 7.7640e-02, 1.0716e-01,\n",
       "         0.0000e+00, 1.4198e-02, 1.8456e-01, 2.6801e-02, 9.0520e-02, 6.3966e-02,\n",
       "         5.1138e-03, 5.5468e-03, 5.8350e-02, 1.5249e-02, 1.0000e+00, 5.8857e-02,\n",
       "         8.3167e-02, 3.3850e-02, 8.4162e-02, 5.0929e-02, 9.1505e-02],\n",
       "        [2.5301e-01, 7.0494e-02, 2.4861e-01, 2.5261e-01, 2.5164e-02, 1.8115e-01,\n",
       "         1.1999e-01, 5.6296e-02, 1.3461e-01, 2.4151e-01, 2.4419e-01, 2.8332e-01,\n",
       "         1.3065e-01, 4.7259e-02, 2.9718e-01, 8.8987e-02, 2.7954e-01, 1.7463e-01,\n",
       "         2.5605e-02, 2.9278e-02, 1.3861e-01, 1.3184e-01, 1.0000e+00, 1.1439e-01,\n",
       "         2.5063e-01, 1.9321e-01, 2.4684e-01, 1.6099e-01, 2.2813e-01],\n",
       "        [1.5356e-01, 2.6743e-02, 1.6355e-01, 1.4653e-01, 1.5101e-02, 1.0342e-01,\n",
       "         1.0601e-01, 2.3844e-02, 0.0000e+00, 1.5218e-01, 1.5441e-01, 1.6613e-01,\n",
       "         7.0865e-04, 1.7603e-02, 2.3436e-01, 6.1595e-02, 1.7753e-01, 1.2726e-01,\n",
       "         9.6233e-03, 6.8085e-03, 3.5004e-02, 3.9319e-02, 1.0000e+00, 8.9073e-02,\n",
       "         1.5138e-01, 7.3516e-02, 1.6386e-01, 4.2372e-02, 7.8316e-02],\n",
       "        [2.0061e-01, 5.8901e-02, 2.0148e-01, 1.9533e-01, 2.0819e-02, 1.2150e-01,\n",
       "         9.1889e-02, 3.7007e-02, 1.7540e-02, 1.9748e-01, 2.1577e-01, 2.2827e-01,\n",
       "         0.0000e+00, 3.5231e-02, 2.4563e-01, 1.1641e-01, 2.0024e-01, 1.3808e-01,\n",
       "         1.5355e-02, 1.8239e-02, 4.5649e-02, 5.9231e-02, 1.0000e+00, 9.6643e-02,\n",
       "         1.9814e-01, 5.3808e-01, 1.7435e-01, 7.5263e-02, 1.4868e-01],\n",
       "        [9.2427e-02, 3.1187e-02, 8.5081e-02, 8.8253e-02, 2.5471e-02, 6.4657e-02,\n",
       "         8.7187e-02, 3.3332e-05, 0.0000e+00, 9.7802e-02, 6.6808e-02, 1.1386e-01,\n",
       "         0.0000e+00, 7.2185e-03, 1.9594e-01, 4.1522e-02, 1.2835e-01, 7.3791e-02,\n",
       "         2.8372e-03, 1.5616e-03, 5.2440e-02, 3.9740e-02, 1.0000e+00, 5.2138e-02,\n",
       "         9.1396e-02, 9.5489e-02, 8.9893e-02, 5.8003e-02, 3.3618e-02]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  8,  12,   7,  19,  18,  13,   4,   1,  28,  21,  15,  23,  20,  27,\n",
      "           5,  10,  17,   2,   6,   3,  26,  24,   0,  25,   9,  11,  16,  14,\n",
      "          22],\n",
      "        [ 37,  41,  36,  48,  47,  42,  33,  30,  57,  50,  44,  52,  49,  56,\n",
      "          34,  39,  46,  31,  35,  32,  55,  53,  29,  54,  38,  40,  45,  43,\n",
      "          51],\n",
      "        [ 66,  70,  65,  77,  76,  71,  62,  59,  86,  79,  73,  81,  78,  85,\n",
      "          63,  68,  75,  60,  64,  61,  84,  82,  58,  83,  67,  69,  74,  72,\n",
      "          80],\n",
      "        [ 95,  99,  94, 106, 105, 100,  91,  88, 115, 108, 102, 110, 107, 114,\n",
      "          92,  97, 104,  89,  93,  90, 113, 111,  87, 112,  96,  98, 103, 101,\n",
      "         109],\n",
      "        [124, 128, 123, 135, 134, 129, 120, 117, 144, 137, 131, 139, 136, 143,\n",
      "         121, 126, 133, 118, 122, 119, 142, 140, 116, 141, 125, 127, 132, 130,\n",
      "         138],\n",
      "        [153, 157, 152, 164, 163, 158, 149, 146, 173, 166, 160, 168, 165, 172,\n",
      "         150, 155, 162, 147, 151, 148, 171, 169, 145, 170, 154, 156, 161, 159,\n",
      "         167],\n",
      "        [182, 186, 181, 193, 192, 187, 178, 175, 202, 195, 189, 197, 194, 201,\n",
      "         179, 184, 191, 176, 180, 177, 200, 198, 174, 199, 183, 185, 190, 188,\n",
      "         196],\n",
      "        [211, 215, 210, 222, 221, 216, 207, 204, 231, 224, 218, 226, 223, 230,\n",
      "         208, 213, 220, 205, 209, 206, 229, 227, 203, 228, 212, 214, 219, 217,\n",
      "         225],\n",
      "        [240, 244, 239, 251, 250, 245, 236, 233, 260, 253, 247, 255, 252, 259,\n",
      "         237, 242, 249, 234, 238, 235, 258, 256, 232, 257, 241, 243, 248, 246,\n",
      "         254],\n",
      "        [269, 273, 268, 280, 279, 274, 265, 262, 289, 282, 276, 284, 281, 288,\n",
      "         266, 271, 278, 263, 267, 264, 287, 285, 261, 286, 270, 272, 277, 275,\n",
      "         283]])\n"
     ]
    }
   ],
   "source": [
    "test = [9.2427e-02, 3.1187e-02, 8.5081e-02, 8.8253e-02, 2.5471e-02, 6.4657e-02,\n",
    "         8.7187e-02, 3.3332e-05, 0.0000e+00, 9.7802e-02, 6.6808e-02, 1.1386e-01,\n",
    "         0.0000e+00, 7.2185e-03, 1.9594e-01, 4.1522e-02, 1.2835e-01, 7.3791e-02,\n",
    "         2.8372e-03, 1.5616e-03, 5.2440e-02, 3.9740e-02, 1.0000e+00, 5.2138e-02,\n",
    "         9.1396e-02, 9.5489e-02, 8.9893e-02, 5.8003e-02, 3.3618e-02]\n",
    "\n",
    "\n",
    "\n",
    "print(construct_noOverlap_indices(torch.tensor(test, dtype = torch.float32), 10, 29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"./trained_weights.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': 50,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': criterion,\n",
    "            }, \"./trained_weights_nosending5.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-012362d859f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Prep the batch for a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mbatchObs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m#batchObs = [i for i in range(0, batchSize)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmodelX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchObs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/caoe/lib/python3.6/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for t in range(epochs):\n",
    "    for k in range(math.ceil(len(y)/batchSize)):\n",
    "        # Prep the batch for a forward pass\n",
    "        batchObs = random.sample(range(0, len(y)), batchSize)\n",
    "        #batchObs = [i for i in range(0, batchSize)]\n",
    "        modelX = X[batchObs]\n",
    "        modelX = torch.tensor(list(modelX), requires_grad = True, dtype = torch.float32)\n",
    "        modely = torch.reshape(torch.tensor(y[batchObs], dtype = torch.float32), (batchSize,1))\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(modelX, t)\n",
    "        loss = criterion(y_pred, modely)  \n",
    "        \n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        grad = torch.autograd.grad(outputs=loss, inputs=modelX, retain_graph = True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the coordinate weights\n",
    "        # https://discuss.pytorch.org/t/updatation-of-parameters-without-using-optimizer-step/34244/4\n",
    "        with torch.no_grad():\n",
    "            for name, p in model.named_parameters():\n",
    "                if name == 'SocialSig.W':\n",
    "                    new_val = update_function(p, grad[0], loss, lr)\n",
    "                    p.copy_(new_val)\n",
    "        \n",
    "\n",
    "        print(\"Epoch: \" + str(t) + \" Batch: \" + str(k))\n",
    "        print(\"    Loss:     \", loss.item(), \"     MAE: \", mae(y_pred, modely).item())\n",
    "        print(\"\\n\")\n",
    "\n",
    "        if loss.item() < 0:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caoe",
   "language": "python",
   "name": "caoe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
