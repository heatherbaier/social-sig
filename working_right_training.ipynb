{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import sklearn\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "\n",
    "import socialSig\n",
    "importlib.reload(socialSig)\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sending_citizen_unspecified  sending_citizenship_unknown  \\\n",
      "0                  1134.995083                   243.827586   \n",
      "1                   917.067746                   600.000000   \n",
      "2                   637.977315                   557.150000   \n",
      "3                  1178.378744                  1678.562500   \n",
      "4                  2231.128863                  2916.538705   \n",
      "\n",
      "   sending_household_not_owned  sending_household_owned  \\\n",
      "0                  1178.209016              1106.832815   \n",
      "1                  1274.160656               795.118020   \n",
      "2                   729.454795               610.791414   \n",
      "3                  1560.244328              1084.109969   \n",
      "4                  2104.943216              2278.834178   \n",
      "\n",
      "   sending_household_owned_unknown  sending_indigeneity  sending_internet  \\\n",
      "0                       736.562500           918.960526       2111.233685   \n",
      "1                        -1.000000            -1.000000       1988.103175   \n",
      "2                       468.392857           584.454545       1310.462428   \n",
      "3                       785.742857          1165.943463       2109.431851   \n",
      "4                      2353.519005          2527.268790       3075.771459   \n",
      "\n",
      "   sending_internet_unknown  sending_marriage_unknown  sending_married  ...  \\\n",
      "0                347.698113                576.362069      1921.620722  ...   \n",
      "1                459.166667                342.800000      1383.286109  ...   \n",
      "2                514.312500               3800.000000      1079.759162  ...   \n",
      "3               1043.500000                549.695652      1945.953046  ...   \n",
      "4               1941.578834                650.206897      3749.195659  ...   \n",
      "\n",
      "   sending_unknown_employment_status  sending_unknown_indigeneity  \\\n",
      "0                        1218.357143                   840.339623   \n",
      "1                         535.750000                   576.379310   \n",
      "2                         540.000000                   629.215385   \n",
      "3                         771.400000                   694.579439   \n",
      "4                        1531.622086                  2064.311411   \n",
      "\n",
      "   sending_unpaid_worker  sending_urban  sending_weighted_avg_income  \\\n",
      "0                      0    1597.239059                  1124.200953   \n",
      "1                      0      -1.000000                   908.782316   \n",
      "2                      0      -1.000000                   628.585520   \n",
      "3                      0    1436.934837                  1173.751889   \n",
      "4                      0    2319.113608                  2230.022635   \n",
      "\n",
      "   sending_weighted_avg_income_abroad  sending_weighted_avg_no_income_abroad  \\\n",
      "0                          768.788518                            1213.505104   \n",
      "1                          720.767123                             929.317603   \n",
      "2                          486.116034                             738.533015   \n",
      "3                          861.385645                            1219.547797   \n",
      "4                         1672.340116                            2273.630651   \n",
      "\n",
      "   sending_weighted_avg_unknown_income_abroad  sending_widowed  US_MIG_05_10  \n",
      "0                                 1931.825000       460.430041           961  \n",
      "1                                  845.567568       745.377359           154  \n",
      "2                                   -1.000000       276.569767           905  \n",
      "3                                 1643.137255       741.363985           225  \n",
      "4                                 3946.180995      1241.236982          1071  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "####### Load our Data\n",
    "#y - 'number_moved'\n",
    "#x - 'everything else that is or can be represented as a float.'\n",
    "devSet = pd.read_csv(\"./us_migration.csv\")\n",
    "devSet = devSet.loc[:, ~devSet.columns.str.contains('^Unnamed')]\n",
    "devSet = devSet.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "devSet = devSet.dropna(axis=1)\n",
    "devSet = devSet.drop(['sending'], axis = 1)\n",
    "\n",
    "print(devSet.head())\n",
    "\n",
    "y = torch.Tensor(devSet['US_MIG_05_10'].values)\n",
    "X = devSet.loc[:, devSet.columns != \"US_MIG_05_10\"].values\n",
    "\n",
    "mMScale = preprocessing.MinMaxScaler()\n",
    "X = mMScale.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, split):\n",
    "\n",
    "    train_num = int(len(X) * split)\n",
    "    val_num = int(len(X) - train_num)\n",
    "\n",
    "    train_indices = random.sample(range(len(X)), train_num)\n",
    "    val_indices = [i for i in range(len(X)) if i not in train_indices]\n",
    "\n",
    "    x_train, x_val = X[train_indices], X[val_indices]\n",
    "    y_train, y_val = y[val_indices], y[val_indices]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Build and fit the Model\n",
    "lr = 1e-6\n",
    "batchSize = 50\n",
    "model = socialSig.SocialSigNet(X=X, outDim = batchSize)\n",
    "epochs = 1\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = train_test_split(X, y, .80)\n",
    "\n",
    "train = [(k,v) for k,v in zip(x_train, y_train)]\n",
    "val = [(k,v) for k,v in zip(x_val, y_val)]\n",
    "\n",
    "train = torch.utils.data.DataLoader(train, batch_size = batchSize, shuffle = True)\n",
    "val = torch.utils.data.DataLoader(val, batch_size = batchSize, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/heatherbaier/Desktop/CAOE/sig/socialSig.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(\"    W at beginning: \", torch.tensor(self.W))\n",
      "/Users/heatherbaier/Desktop/CAOE/sig/socialSig.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  taken = torch.take(batchX, construct_noOverlap_indices(torch.tensor(self.W, dtype = torch.float32), batchX.shape[0], self.W.shape[0]))\n",
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/torch/nn/functional.py:3455: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "    W at beginning:  tensor([2.1385e-02, 9.4206e-03, 9.6362e-02, 5.3210e-02, 1.4519e-05, 4.7531e-02,\n",
      "        8.8082e-02, 3.7379e-02, 8.0122e-02, 6.7977e-02, 6.6265e-03, 3.3945e-02,\n",
      "        6.7518e-02, 6.7380e-02, 5.9933e-02, 2.2598e-02, 7.0929e-02, 1.1315e-02,\n",
      "        7.4608e-02, 8.8387e-02, 4.0019e-02, 9.5174e-02, 6.5706e-02, 3.0055e-02,\n",
      "        5.6044e-02, 3.6465e-02, 7.0851e-02, 6.7270e-02, 8.3068e-02])\n",
      "    W at beginning:  tensor([2.1305e-02, 9.4286e-03, 9.6977e-02, 5.4738e-02, 1.7783e-05, 4.7232e-02,\n",
      "        8.8646e-02, 3.7940e-02, 8.0588e-02, 6.7504e-02, 6.7540e-03, 3.3867e-02,\n",
      "        6.7427e-02, 6.7903e-02, 6.0355e-02, 2.2637e-02, 6.9931e-02, 1.1264e-02,\n",
      "        7.4695e-02, 8.8060e-02, 4.0224e-02, 9.5238e-02, 6.5812e-02, 2.9787e-02,\n",
      "        5.6330e-02, 3.6731e-02, 7.1019e-02, 6.6993e-02, 8.2748e-02])\n",
      "    W at beginning:  tensor([0.0216, 0.0102, 0.0981, 0.0560, 0.0019, 0.0474, 0.0877, 0.0407, 0.0828,\n",
      "        0.0697, 0.0086, 0.0349, 0.0689, 0.0705, 0.0572, 0.0095, 0.0693, 0.0109,\n",
      "        0.0757, 0.0845, 0.0388, 0.0969, 0.0673, 0.0299, 0.0563, 0.0360, 0.0783,\n",
      "        0.0685, 0.0835])\n",
      "    W at beginning:  tensor([ 0.0133, -0.0274,  0.0351,  0.0858,  0.0067,  0.0536,  0.0031,  0.1435,\n",
      "         0.0078,  0.0901,  0.0261,  0.0372,  0.0571,  0.2707,  0.1183,  0.0093,\n",
      "         0.0814,  0.0175,  0.0060,  0.0457,  0.0129,  0.0966,  0.0487,  0.0291,\n",
      "         0.0336,  0.0381,  0.0632,  0.0694,  0.0691])\n",
      "    W at beginning:  tensor([ 0.0149, -0.0264,  0.0383,  0.0910,  0.0096,  0.0545,  0.0045,  0.1436,\n",
      "         0.0112,  0.0941,  0.0245,  0.0367,  0.0577,  0.2694,  0.1264,  0.0181,\n",
      "         0.0827,  0.0185,  0.0084,  0.0462,  0.0170,  0.1037,  0.0454,  0.0271,\n",
      "         0.0348,  0.0390,  0.0634,  0.0648,  0.0572])\n",
      "    W at beginning:  tensor([ 0.0119, -0.0284,  0.0336,  0.0882,  0.0080,  0.0553,  0.0029,  0.1432,\n",
      "         0.0123,  0.0991,  0.0362,  0.0397,  0.0587,  0.2684,  0.1371,  0.0147,\n",
      "         0.0793,  0.0211,  0.0075,  0.0447,  0.0214,  0.1233,  0.0558,  0.0280,\n",
      "         0.0344,  0.0353,  0.0625,  0.0673,  0.0526])\n",
      "    W at beginning:  tensor([ 1.1235e-02, -2.9630e-02,  3.1480e-02,  8.7979e-02,  7.9155e-03,\n",
      "         5.5984e-02, -9.6700e-05,  1.4613e-01,  1.1534e-02,  9.9155e-02,\n",
      "         3.3357e-02,  3.7526e-02,  5.8076e-02,  2.7287e-01,  1.3960e-01,\n",
      "         1.6952e-02,  7.8866e-02,  2.2443e-02,  9.0616e-03,  4.2746e-02,\n",
      "         2.0933e-02,  1.2510e-01,  5.5445e-02,  2.7335e-02,  3.5099e-02,\n",
      "         3.4919e-02,  6.2386e-02,  6.7636e-02,  5.3532e-02])\n",
      "    W at beginning:  tensor([ 0.0060, -0.0247,  0.0212,  0.0901,  0.0084,  0.0724, -0.0204,  0.1327,\n",
      "         0.0251,  0.0973,  0.0161,  0.0520,  0.0424,  0.3010,  0.1730,  0.0251,\n",
      "         0.0704,  0.0504,  0.0027,  0.0399,  0.0219,  0.1170,  0.0118,  0.0112,\n",
      "         0.0348,  0.0390,  0.0593,  0.0681,  0.0550])\n",
      "    W at beginning:  tensor([ 0.0088, -0.0266,  0.0206,  0.0899,  0.0085,  0.0724,  0.0033,  0.1300,\n",
      "         0.0220,  0.0961,  0.0160,  0.0519,  0.0488,  0.2994,  0.1710,  0.0211,\n",
      "         0.0696,  0.0502,  0.0022,  0.0384,  0.0152,  0.1134,  0.0114,  0.0110,\n",
      "         0.0347,  0.0392,  0.0578,  0.0651,  0.0549])\n",
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/ipykernel_launcher.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "    W at beginning:  tensor([ 0.0114, -0.0293,  0.0205,  0.0906,  0.0087,  0.0729,  0.0042,  0.1181,\n",
      "         0.0211,  0.0962,  0.0164,  0.0528,  0.0474,  0.2964,  0.1709,  0.0216,\n",
      "         0.0699,  0.0503,  0.0016,  0.0387,  0.0154,  0.1112,  0.0114,  0.0112,\n",
      "         0.0349,  0.0400,  0.0589,  0.0646,  0.0560])\n",
      "Epoch:  0\n",
      "  Train:\n",
      "    Loss:  9838980.6\n",
      "    MAE:  239.91559906005858\n",
      "  Val:\n",
      "    Loss:  9814683.45\n",
      "    MAE:  217.92244720458984\n"
     ]
    }
   ],
   "source": [
    "best_mae = 9000000000000000000\n",
    "best_model_wts = deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    for phase in ['train','val']:\n",
    "\n",
    "\n",
    "\n",
    "        if phase == 'train':\n",
    "\n",
    "            c = 1\n",
    "            running_train_mae, running_train_loss = 0, 0\n",
    "\n",
    "            # print(\"In training\")\n",
    "\n",
    "            for inputs, output in train:\n",
    "\n",
    "                if len(inputs) == batchSize:\n",
    "\n",
    "                    # print(c)\n",
    "                    c += 1\n",
    "\n",
    "                    inputs = torch.tensor(inputs, dtype = torch.float32, requires_grad = True)\n",
    "                    output = torch.reshape(torch.tensor(output, dtype = torch.float32, requires_grad = True), (batchSize,1))\n",
    "\n",
    "                    # Forward pass\n",
    "                    y_pred = model(inputs, str(epoch) + str(c))\n",
    "                    loss = criterion(y_pred, output)  \n",
    "                    \n",
    "                    # Zero gradients, perform a backward pass, and update the weights.\n",
    "                    optimizer.zero_grad()\n",
    "                    grad = torch.autograd.grad(outputs = loss, inputs = inputs, retain_graph = True)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Update the coordinate weights\n",
    "                    # https://discuss.pytorch.org/t/updatation-of-parameters-without-using-optimizer-step/34244/4\n",
    "                    with torch.no_grad():\n",
    "                        for name, p in model.named_parameters():\n",
    "                            if name == 'SocialSig.W':\n",
    "                                new_val = update_function(p, grad[0], loss, lr)\n",
    "                                p.copy_(new_val)\n",
    "\n",
    "                    running_train_mae += mae(y_pred, output).item()\n",
    "                    running_train_loss += loss.item()\n",
    "\n",
    "        if phase == 'val':\n",
    "\n",
    "            c = 1\n",
    "            running_val_mae, running_val_loss,  = 0, 0\n",
    "\n",
    "            # print(\"In validation\")\n",
    "\n",
    "            for inputs, output in val:\n",
    "\n",
    "                if len(inputs) == batchSize:\n",
    "\n",
    "                    # print(c)\n",
    "                    c += 1\n",
    "\n",
    "                    inputs = torch.tensor(inputs, dtype = torch.float32, requires_grad = True)\n",
    "                    output = torch.reshape(torch.tensor(output, dtype = torch.float32, requires_grad = True), (batchSize,1))\n",
    "\n",
    "                    # Forward pass\n",
    "                    y_pred = model(inputs, 1)\n",
    "                    loss = criterion(y_pred, output)  \n",
    "\n",
    "                    running_val_mae += mae(y_pred, output).item()\n",
    "                    running_val_loss += loss.item()\n",
    "                    \n",
    "                    if mae(y_pred, output).item() < best_mae:\n",
    "                        best_mae = mae(y_pred, output).item()\n",
    "                        best_model_wts = deepcopy(model.state_dict())\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "    print(\"Epoch: \", epoch)  \n",
    "    print(\"  Train:\")\n",
    "    print(\"    Loss: \", running_train_loss / c)      \n",
    "    print(\"    MAE: \", running_train_mae / c)\n",
    "    print(\"  Val:\")\n",
    "    print(\"    Loss: \", running_val_loss / c)      \n",
    "    print(\"    MAE: \", running_val_mae / c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': 50,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': criterion,\n",
    "            }, \"./trained_weights_nosending5.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caoe",
   "language": "python",
   "name": "caoe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}