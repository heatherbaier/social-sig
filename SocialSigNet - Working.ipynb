{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import pytorchvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SocialSig(torch.nn.Module):\n",
    "    '''\n",
    "    Class to create the social signature image\n",
    "    '''\n",
    "    def __init__(self, X, W):\n",
    "        super(SocialSig, self).__init__()\n",
    "        self.W = W\n",
    "        self.outDim = [10,10]\n",
    "        self.inDim = math.ceil(math.sqrt(len(X)))\n",
    "        self.X = X\n",
    "        \n",
    "\n",
    "    def forward(self):\n",
    "        xTemp = torch.stack([self.X, self.W])\n",
    "        X = torch.sort(xTemp, dim=1, descending=False)\n",
    "        buildImage = torch.reshape(X[0][0],(1, 1, self.inDim, self.inDim))\n",
    "        return torch.nn.functional.interpolate(buildImage, size=([self.outDim[0], self.outDim[1]]), mode='bilinear')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SocialSigNet(torch.nn.Module):\n",
    "    def __init__(self, X):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate four parameters and assign them as\n",
    "        member parameters.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.W = torch.nn.Parameter(torch.tensor(np.arange(0,len(X)), dtype = torch.float32, requires_grad=True))\n",
    "        self.SocialSig = SocialSig(X,self.W)                \n",
    "        self.maxPool = torch.nn.MaxPool2d(kernel_size=(10,10))  #10,10 is static here.  Will need to be dynamic based on user dim settings.\n",
    "\n",
    "    def forward(self, X):\n",
    "        print(\"    W at beginning: \", self.W.data)\n",
    "        out = self.SocialSig()\n",
    "        out = self.maxPool(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([0., 1., 2., 3.], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# Create random tensors to hold input and outputs.\n",
    "X = torch.tensor([-1.6848, -0.6, -93.2, -182.2], requires_grad = True)\n",
    "y = torch.tensor([0.0359], requires_grad = True)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = SocialSigNet(X=X)\n",
    "#print(dir(model))\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "\n",
    "# make_dot(model(X), params=dict(list(model.named_parameters()))).render(\"backPropViz\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  0\n",
      "    W at beginning:  tensor([0., 1., 2., 3.])\n",
      "    Predicted Y:     tensor([[[[-0.6000]]]], grad_fn=<MaxPool2DWithIndicesBackward>)\n",
      "    Loss:            tensor([[[[0.4044]]]], grad_fn=<MseLossBackward>)\n",
      "    Gradient:        tensor([ 0.0000, -1.2718,  0.0000,  0.0000])\n",
      "    In with:         tensor([0., 1., 2., 3.])\n",
      "\n",
      "\n",
      "EPOCH:  1\n",
      "    W at beginning:  tensor([ 0.0000, 13.7180,  2.0000,  3.0000])\n",
      "    Predicted Y:     tensor([[[[-0.6000]]]], grad_fn=<MaxPool2DWithIndicesBackward>)\n",
      "    Loss:            tensor([[[[0.4044]]]], grad_fn=<MseLossBackward>)\n",
      "    Gradient:        tensor([ 0.0000, -1.2718,  0.0000,  0.0000])\n",
      "    In with:         tensor([ 0.0000, 13.7180,  2.0000,  3.0000])\n",
      "\n",
      "\n",
      "EPOCH:  2\n",
      "    W at beginning:  tensor([ 0.0000, 26.4360,  2.0000,  3.0000])\n",
      "    Predicted Y:     tensor([[[[-0.6000]]]], grad_fn=<MaxPool2DWithIndicesBackward>)\n",
      "    Loss:            tensor([[[[0.4044]]]], grad_fn=<MseLossBackward>)\n",
      "    Gradient:        tensor([ 0.0000, -1.2718,  0.0000,  0.0000])\n",
      "    In with:         tensor([ 0.0000, 26.4360,  2.0000,  3.0000])\n",
      "\n",
      "\n",
      "EPOCH:  3\n",
      "    W at beginning:  tensor([ 0.0000, 39.1540,  2.0000,  3.0000])\n",
      "    Predicted Y:     tensor([[[[-0.6000]]]], grad_fn=<MaxPool2DWithIndicesBackward>)\n",
      "    Loss:            tensor([[[[0.4044]]]], grad_fn=<MseLossBackward>)\n",
      "    Gradient:        tensor([ 0.0000, -1.2718,  0.0000,  0.0000])\n",
      "    In with:         tensor([ 0.0000, 39.1540,  2.0000,  3.0000])\n",
      "\n",
      "\n",
      "EPOCH:  4\n",
      "    W at beginning:  tensor([ 0.0000, 51.8720,  2.0000,  3.0000])\n",
      "    Predicted Y:     tensor([[[[-0.6000]]]], grad_fn=<MaxPool2DWithIndicesBackward>)\n",
      "    Loss:            tensor([[[[0.4044]]]], grad_fn=<MseLossBackward>)\n",
      "    Gradient:        tensor([ 0.0000, -1.2718,  0.0000,  0.0000])\n",
      "    In with:         tensor([ 0.0000, 51.8720,  2.0000,  3.0000])\n",
      "\n",
      "\n",
      "Model.parameters\n",
      "<bound method Module.parameters of SocialSigNet(\n",
      "  (SocialSig): SocialSig()\n",
      "  (maxPool): MaxPool2d(kernel_size=(10, 10), stride=(10, 10), padding=0, dilation=1, ceil_mode=False)\n",
      ")>\n",
      "SSParam\n",
      "[Parameter containing:\n",
      "tensor([ 0.0000, 64.5900,  2.0000,  3.0000], requires_grad=True)]\n",
      "is_leaf\n",
      "True\n",
      "gradfn\n",
      "None\n",
      "Grad\n",
      "tensor([0., 0., 0., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/torch/nn/functional.py:3455: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Setting the LR to something dumb just to test that things are indeed working\n",
    "lr = 10\n",
    "criterion = torch.nn.MSELoss(reduction='none')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "\n",
    "\n",
    "def update_function(param, grad, loss, learning_rate):\n",
    "    return param - learning_rate * grad\n",
    "\n",
    "\n",
    "for t in range(5):\n",
    "    print(\"EPOCH: \", t)\n",
    "    y_pred = model(X)\n",
    "    print(\"    Predicted Y:    \", y_pred)\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(\"    Loss:           \", loss)\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    grad = torch.autograd.grad(outputs=loss, inputs=X, retain_graph = True)\n",
    "    print(\"    Gradient:       \", grad[0])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # https://discuss.pytorch.org/t/updatation-of-parameters-without-using-optimizer-step/34244/4\n",
    "    with torch.no_grad():\n",
    "        for p in model.parameters():\n",
    "            print(\"    In with:        \", p.data)\n",
    "            new_val = update_function(p, grad[0], loss, lr)\n",
    "            p.copy_(new_val)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"Model.parameters\")\n",
    "print(model.parameters)\n",
    "print(\"SSParam\")\n",
    "print(list(model.SocialSig.parameters()))\n",
    "print(\"is_leaf\")\n",
    "print(list(model.SocialSig.parameters())[0].is_leaf)\n",
    "print(\"gradfn\")\n",
    "print(list(model.SocialSig.parameters())[0].grad_fn)\n",
    "print(\"Grad\")\n",
    "print(list(model.SocialSig.parameters())[0].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caoe",
   "language": "python",
   "name": "caoe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
