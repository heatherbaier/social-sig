{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import openturns as ot\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import random\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SocialSig(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SocialSig, self).__init__()\n",
    "#         # self.weight = torch.nn.Parameter(data=torch.Tensor(1, 1, 1, 1), requires_grad=True)\n",
    "#         self.weight = torch.nn.Parameter(torch.randn(()))\n",
    "        \n",
    "# #         self.weight.data.uniform_(-1, 1)\n",
    "\n",
    "\n",
    "#     def __train_krigging(self, points, coords, weight):\n",
    "#         '''\n",
    "#         Train the krigging model to predict all of the points that are between known points\n",
    "#         '''\n",
    "        \n",
    "#         random.Random(weight).shuffle(points)\n",
    "        \n",
    "#         coordinates_train = ot.Sample(coords)\n",
    "#         data_train = ot.Sample(points) # At 2000/1/2\n",
    "#         inputDimension = 2\n",
    "#         basis = ot.ConstantBasisFactory(inputDimension).build()\n",
    "#         covarianceModel = ot.SquaredExponential([1.]*inputDimension, [1.0])\n",
    "#         algo = ot.KrigingAlgorithm(coordinates_train, data_train, covarianceModel, basis)\n",
    "#         algo.run()\n",
    "#         result = algo.getResult()\n",
    "#         krigingMetamodel = result.getMetaModel()\n",
    "#         return [krigingMetamodel, points]\n",
    "    \n",
    "    \n",
    "#     def __make_blank_coord_grid(self, n_rows):\n",
    "#         '''\n",
    "#         Make a blank coordinate grid to fill in with real data later\n",
    "#         '''\n",
    "#         return [[x,y] for x in range(0, 4) for y in range(0,4)]\n",
    "            \n",
    "\n",
    "#     def __make_real_data_set(self, blank_grid, points, coords, krigingMetamodel):\n",
    "#         '''\n",
    "#         Fill in the blank grid with real data.\n",
    "#         If the coordinate pair is in the list that has real data, give the coord real data.\n",
    "#         If not, krig it.\n",
    "#         '''\n",
    "        \n",
    "#         to_return = [(points[coords.index(i)][0]) if i in coords else list(krigingMetamodel(i))[0] for i in blank_grid]\n",
    "#         to_return = torch.from_numpy(np.reshape(np.array(to_return), (1,1,4,4)))\n",
    "#         to_return = torch.tensor(to_return, dtype=torch.float)\n",
    "\n",
    "#         return to_return\n",
    "    \n",
    "#     def process(self, x, coords, weight):\n",
    "# #         self.__points, self.__coords = self.__make_training_data(num_known_points, n_rows, seed)\n",
    "#         krig, points = self.__train_krigging(x, coords, self.weight)\n",
    "#         blank_grid = self.__make_blank_coord_grid(2)\n",
    "#         real_dataset = self.__make_real_data_set(blank_grid, points, coords, krig)\n",
    "        \n",
    "#         return real_dataset\n",
    "\n",
    "        \n",
    "    \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         print(\"WEIGHT: \", self.weight)\n",
    "        \n",
    "#         coords = [(list(np.random.randint(low = 0, high = math.sqrt(len(x)), size = 2))) for i in range(0, len(x))]        \n",
    "# #         self.process(x, coords, self.weight)\n",
    "#         return self.process(x, coords, self.weight) * 1\n",
    "\n",
    "\n",
    "\n",
    "class SocialSig():\n",
    "    \n",
    "    '''\n",
    "    Class to create the social signature image\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, num_known_points, n_rows, seed, coords):\n",
    "        '''\n",
    "        Basic steps for class:\n",
    "            1. Randomly initalize 'weights' which I believe are actually the coords of the points\n",
    "            2. Train kriggin model to interpolate points in between\n",
    "            3. Predict what the points would be within a 224x224 matrix and output the resulting matrix\n",
    "        '''\n",
    "        \n",
    "        self.w = torch.nn.Parameter(torch.tensor(1, dtype = torch.float32)) \n",
    "        \n",
    "#         self.__coords = coords.numpy()\n",
    "        self.__coords = [list(i) for i in list(coords.numpy())]\n",
    "#         print(self.__coords)\n",
    "#         print(coords.numpy().shape)\n",
    "#         for i in coords.numpy():\n",
    "#             print(i)\n",
    "        self.__points = self.__make_training_data(num_known_points, n_rows, seed)\n",
    "        self.__krig = self.__train_krigging(self.__points, self.__coords)\n",
    "        self.__blank_grid = self.__make_blank_coord_grid(n_rows)\n",
    "        self.real_dataset = self.__make_real_data_set(self.__blank_grid, self.__points, self.__coords, self.__krig)\n",
    "        \n",
    "        \n",
    "    def __make_training_data(self, num_known_points, n_rows, seed):\n",
    "        '''\n",
    "        Create the training dataset by randomly assigning coordiantes to the known data (i.e the data within a row)\n",
    "        '''\n",
    "#         points = [[i] for i in list(np.random.randint(low = 0, high = 255, size = num_known_points).flatten())]\n",
    "#         coords = [(list(np.random.randint(low = 0, high = n_rows, size = 2))) for i in range(0, num_known_points)]\n",
    "        points = [[60], [48], [151], [52], [95], [135], [184], [199]]\n",
    "        random.Random(seed).shuffle(points)\n",
    "#         coords = [[0, 2], [1, 0], [3, 1], [1, 0], [0, 3], [2, 0], [3, 0], [3, 2]]\n",
    "        return points\n",
    "    \n",
    "    \n",
    "    def __train_krigging(self, points, coords):\n",
    "        '''\n",
    "        Train the krigging model to predict all of the points that are between known points\n",
    "        '''\n",
    "        coordinates_train = ot.Sample(coords)\n",
    "        data_train = ot.Sample(points) # At 2000/1/2\n",
    "        inputDimension = 2\n",
    "        basis = ot.ConstantBasisFactory(inputDimension).build()\n",
    "        covarianceModel = ot.SquaredExponential([1.]*inputDimension, [1.0])\n",
    "        algo = ot.KrigingAlgorithm(coordinates_train, data_train, covarianceModel, basis)\n",
    "        algo.run()\n",
    "        result = algo.getResult()\n",
    "        krigingMetamodel = result.getMetaModel()\n",
    "        return krigingMetamodel\n",
    "    \n",
    "    \n",
    "    def __make_blank_coord_grid(self, n_rows):\n",
    "        '''\n",
    "        Make a blank coordinate grid to fill in with real data later\n",
    "        '''\n",
    "        return [[x,y] for x in range(0, 4) for y in range(0,4)]\n",
    "            \n",
    "\n",
    "    def __make_real_data_set(self, blank_grid, points, coords, krigingMetamodel):\n",
    "        '''\n",
    "        Fill in the blank grid with real data.\n",
    "        If the coordinate pair is in the list that has real data, give the coord real data.\n",
    "        If not, krig it.\n",
    "        '''\n",
    "        \n",
    "        to_return = [(points[coords.index(i)][0]) if i in coords else list(krigingMetamodel(i))[0] for i in blank_grid]\n",
    "        to_return = torch.from_numpy(np.reshape(np.array(to_return), (1,1,4,4)))\n",
    "        to_return = torch.tensor(to_return, dtype=torch.float)\n",
    "\n",
    "        return to_return * self.w\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'n_rows', 'seed', and 'coords'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-332-ebca018a4e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSocialSig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_example_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'n_rows', 'seed', and 'coords'"
     ]
    }
   ],
   "source": [
    "# SocialSig(make_example_data(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'D_in'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-291-3e68f7dfbd94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mhm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwoLayerNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mhm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/caoe/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'D_in'"
     ]
    }
   ],
   "source": [
    "# class TwoLayerNet(torch.nn.Module):\n",
    "#     def __init__(self, D_in, H, D_out):\n",
    "#         \"\"\"\n",
    "#         In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "#         member variables.\n",
    "#         \"\"\"\n",
    "#         super(TwoLayerNet, self).__init__()\n",
    "#         self.D_in = D_in\n",
    "# #         print(D_in)\n",
    "# #         self.linear1 = torch.nn.Linear(D_in, H)\n",
    "# #         self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "#     def forward(self, x, D_in):\n",
    "#         \"\"\"\n",
    "#         In the forward function we accept a Tensor of input data and we must return\n",
    "#         a Tensor of output data. We can use Modules defined in the constructor as\n",
    "#         well as arbitrary operators on Tensors.\n",
    "#         \"\"\"\n",
    "#         print(x)\n",
    "#         print(self.D_in)\n",
    "#         print('hey')\n",
    "# #         h_relu = self.linear1(x).clamp(min=0)\n",
    "# #         y_pred = self.linear2(h_relu)\n",
    "#         return 1\n",
    "\n",
    "\n",
    "# hm = TwoLayerNet(1,1,1)\n",
    "# hm(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[34], [171], [125], [77]]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THIS IS WHAT YOU WILL USE TO CREATE YOUR INPUT LAYER--THIS SHOULD BE A LIST WITH 81 ELEMENTS (THE ROW IN THE DF)\n",
    "def make_example_data(seed):\n",
    "    '''\n",
    "    Create the training dataset by randomly assigning coordiantes to the known data (i.e the data within a row)\n",
    "    '''\n",
    "    points = [[i] for i in list(np.random.randint(low = 0, high = 255, size = 4).flatten())]\n",
    "#         coords = [(list(np.random.randint(low = 0, high = n_rows, size = 2))) for i in range(0, num_known_points)]\n",
    "#     points = [[60], [48], [151], [52], [95], [135], [184], [199]]\n",
    "#     random.Random(seed).shuffle(points)\n",
    "#     coords = [[0, 2], [1, 0], [3, 1], [1, 0], [0, 3], [2, 0], [3, 0], [3, 2]]\n",
    "    return points\n",
    "\n",
    "\n",
    "make_example_data(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TwoLayerNet(torch.nn.Module):\n",
    "#     def __init__(self, D_in, H, D_out):\n",
    "#         \"\"\"\n",
    "#         In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "#         member variables.\n",
    "#         \"\"\"\n",
    "#         super(TwoLayerNet, self).__init__()\n",
    "#         self.linear1 = torch.nn.Linear(D_in, H)\n",
    "#         self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         In the forward function we accept a Tensor of input data and we must return\n",
    "#         a Tensor of output data. We can use Modules defined in the constructor as\n",
    "#         well as arbitrary operators on Tensors.\n",
    "#         \"\"\"\n",
    "#         h_relu = self.linear1(x).clamp(min=0)\n",
    "#         y_pred = self.linear2(h_relu)\n",
    "#         return y_pred\n",
    "\n",
    "\n",
    "class MakeCoords(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MakeCoords, self).__init__()\n",
    "        # self.weight = torch.nn.Parameter(data=torch.Tensor(1, 1, 1, 1), requires_grad=True)\n",
    "#         self.weight = torch.nn.Parameter(torch.randn(()))\n",
    "        \n",
    "#         self.weight.data.uniform_(-1, 1)\n",
    "\n",
    "        self.x1 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        self.y1 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        \n",
    "        self.x2 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        self.y2 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        \n",
    "        self.x3 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        self.y3 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        \n",
    "        self.x4 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        self.y4 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32))   \n",
    "        \n",
    "        self.x5 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        self.y5 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        \n",
    "        self.x6 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        self.y6 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        \n",
    "        self.x7 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        self.y7 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        \n",
    "        self.x8 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "        self.y8 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32))     \n",
    "                \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        print(\"X1: \", self.x1)\n",
    "        print(\"X2: \", self.x2)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         coords = torch.tensor([[1*self.x1, 1*self.y1], [1*self.x2, 1*self.y2], [1*self.x3, 1*self.y3], \\\n",
    "#                   [1*self.x4, 1*self.y4], [1*self.x5, 1*self.y5], [1*self.x6, 1*self.y6], \\\n",
    "#                   [1*self.x7, 1*self.y7], [1*self.x8, 1*self.y8]])\n",
    "#         print(coords)\n",
    "        \n",
    "#         print(\"WEIGHT: \", self.weight)\n",
    "        \n",
    "#         coords = [(list(np.random.randint(low = 0, high = math.sqrt(len(x)), size = 2))) for i in range(0, len(x))]        \n",
    "# #         self.process(x, coords, self.weight)\n",
    "\n",
    "        ones = torch.tensor([[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]]) * torch.tensor([self.x1, self.x2])\n",
    "        \n",
    "        print(ones)\n",
    "\n",
    "        return ones\n",
    "\n",
    "    \n",
    "class x1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(x1, self).__init__()\n",
    "        self.x1 = torch.nn.Parameter(torch.tensor(random.randint(0,10), dtype = torch.float32)) \n",
    "    \n",
    "    def forward(self, x):  \n",
    "#         print(\"X1: \", self.x1)\n",
    "        return 1 * self.x1\n",
    "    \n",
    "    \n",
    "class x2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(x2, self).__init__()\n",
    "        self.x2 = torch.nn.Parameter(torch.tensor(torch.randn(()))) \n",
    "    \n",
    "    def forward(self, x):        \n",
    "        return 1 * self.x2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "#         self.SocialSig = SocialSig()\n",
    "        self.conv1 = nn.Conv2d(1, 4, 4, 1)\n",
    "        self.linear1 = torch.nn.Linear(4, 1)\n",
    "        self.linear2 = torch.nn.Linear(2, 1)\n",
    "        self.make_coords = MakeCoords()\n",
    "        self.x1 = x1()\n",
    "        self.x2 = x2()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "#         coords = self.make_coords(x)\n",
    "        x1 = self.x1(x)\n",
    "        x2 = self.x2(x)\n",
    "        print(\"X1:\", x1)\n",
    "        print(\"X2:\", x2)\n",
    "        coords = torch.tensor([[x1, x2], [1,2], [2,3], [3,2], [2,4], [4,2], [1,1], [2,2]])\n",
    "        sig = SocialSig(8, 4, 8, coords = coords).real_dataset\n",
    "        print(sig)\n",
    "#         sig = SocialSig(x)\n",
    "#         print(sig)\n",
    "        sig = self.conv1(sig)\n",
    "        sig = torch.flatten(sig, 1)\n",
    "        sig = self.linear1(sig)#.clamp(min=0)\n",
    "#         y_pred = self.linear2(sig)\n",
    "        return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/ipykernel_launcher.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# Construct our model by instantiating the class defined above\n",
    "model = TwoLayerNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([12], dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[171], [16], [211], [122]]\n",
      "X1: tensor(5., grad_fn=<MulBackward0>)\n",
      "X2: tensor(0.1918, grad_fn=<MulBackward0>)\n",
      "tensor([[[[125.4889, 141.6209,  87.1403, 134.8445],\n",
      "          [125.4915, 151.0000,  60.0000, 162.4885],\n",
      "          [125.5522, 141.6209,  52.0000, 184.0000],\n",
      "          [126.1149, 129.5680,  95.0000, 162.4885]]]], grad_fn=<MulBackward0>)\n",
      "PRED:  tensor([[-4.8079]], grad_fn=<AddmmBackward>)\n",
      "LOSS:  tensor(282.5056, grad_fn=<MseLossBackward>)\n",
      "\n",
      "\n",
      "[[171], [16], [211], [122]]\n",
      "X1: tensor(5., grad_fn=<MulBackward0>)\n",
      "X2: tensor(0.1918, grad_fn=<MulBackward0>)\n",
      "tensor([[[[125.4889, 141.6209,  87.1403, 134.8445],\n",
      "          [125.4915, 151.0000,  60.0000, 162.4885],\n",
      "          [125.5522, 141.6209,  52.0000, 184.0000],\n",
      "          [126.1149, 129.5680,  95.0000, 162.4885]]]], grad_fn=<MulBackward0>)\n",
      "PRED:  tensor([[-1.2965]], grad_fn=<AddmmBackward>)\n",
      "LOSS:  tensor(176.7958, grad_fn=<MseLossBackward>)\n",
      "\n",
      "\n",
      "[[171], [16], [211], [122]]\n",
      "X1: tensor(5., grad_fn=<MulBackward0>)\n",
      "X2: tensor(0.1918, grad_fn=<MulBackward0>)\n",
      "tensor([[[[125.4889, 141.6209,  87.1403, 134.8445],\n",
      "          [125.4915, 151.0000,  60.0000, 162.4885],\n",
      "          [125.5522, 141.6209,  52.0000, 184.0000],\n",
      "          [126.1149, 129.5680,  95.0000, 162.4885]]]], grad_fn=<MulBackward0>)\n",
      "PRED:  tensor([[1.4783]], grad_fn=<AddmmBackward>)\n",
      "LOSS:  tensor(110.7067, grad_fn=<MseLossBackward>)\n",
      "\n",
      "\n",
      "[[171], [16], [211], [122]]\n",
      "X1: tensor(5., grad_fn=<MulBackward0>)\n",
      "X2: tensor(0.1918, grad_fn=<MulBackward0>)\n",
      "tensor([[[[125.4889, 141.6209,  87.1403, 134.8445],\n",
      "          [125.4915, 151.0000,  60.0000, 162.4885],\n",
      "          [125.5522, 141.6209,  52.0000, 184.0000],\n",
      "          [126.1149, 129.5680,  95.0000, 162.4885]]]], grad_fn=<MulBackward0>)\n",
      "PRED:  tensor([[3.6738]], grad_fn=<AddmmBackward>)\n",
      "LOSS:  tensor(69.3251, grad_fn=<MseLossBackward>)\n",
      "\n",
      "\n",
      "[[171], [16], [211], [122]]\n",
      "X1: tensor(5., grad_fn=<MulBackward0>)\n",
      "X2: tensor(0.1918, grad_fn=<MulBackward0>)\n",
      "tensor([[[[125.4889, 141.6209,  87.1403, 134.8445],\n",
      "          [125.4915, 151.0000,  60.0000, 162.4885],\n",
      "          [125.5522, 141.6209,  52.0000, 184.0000],\n",
      "          [126.1149, 129.5680,  95.0000, 162.4885]]]], grad_fn=<MulBackward0>)\n",
      "PRED:  tensor([[5.4121]], grad_fn=<AddmmBackward>)\n",
      "LOSS:  tensor(43.4010, grad_fn=<MseLossBackward>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heatherbaier/anaconda/envs/caoe/lib/python3.6/site-packages/ipykernel_launcher.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "x = make_example_data(14)\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)\n",
    "for t in range(5):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    print(x)\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    print(\"PRED: \", y_pred)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(\"LOSS: \", loss)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Make a layer that has a x trainabale params as the coordinates\n",
    "    -- THIS LAYER NEEDS TO HAVE A FORWARD PASS\n",
    "    (https://discuss.pytorch.org/t/pytorch-equivalent-of-keras/29412)\n",
    "'''\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caoe",
   "language": "python",
   "name": "caoe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
