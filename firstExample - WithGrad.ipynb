{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import importlib\n",
    "# import socialSigLayers\n",
    "# importlib.reload(socialSigLayers)\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bilinearImputation(torch.nn.Module):\n",
    "    '''\n",
    "    Class to create the social signature image\n",
    "    '''\n",
    "    def __init__(self, X):\n",
    "        super(bilinearImputation, self).__init__()\n",
    "        self.W = torch.nn.Parameter(torch.tensor(np.arange(0,X.shape[1]), dtype = torch.float32, requires_grad=True))\n",
    "        self.outDim = [10,10]\n",
    "        self.inDim = math.ceil(math.sqrt(X.shape[1]))\n",
    "\n",
    "    def forward(self, batchX):\n",
    "        \n",
    "        # print(\"    W at beginning: \", torch.tensor(self.W, dtype = torch.int)) \n",
    "        print(\"    W at beginning: \", self.W) \n",
    "\n",
    "        self.X = batchX\n",
    "        xTemp = torch.stack([self.X, self.W.clone().repeat(self.X.shape[0],1).data])\n",
    "        XSort, indices = torch.sort(xTemp, dim=1, descending=False)\n",
    "\n",
    "        \n",
    "        inDataSize = XSort[0].shape[1] #Data we have per dimension\n",
    "        targetSize = self.inDim ** 2\n",
    "        paddingOffset = targetSize - inDataSize\n",
    "        paddedInX = torch.nn.functional.pad(input=XSort[0], pad=(0,paddingOffset), mode=\"constant\", value=0)\n",
    "        buildImage = torch.reshape(paddedInX,(self.X.shape[0], 1, self.inDim, self.inDim))   \n",
    "        return torch.nn.functional.interpolate(buildImage, size=([self.outDim[0], self.outDim[1]]), mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Define our model\n",
    "class SocialSigNet(torch.nn.Module):\n",
    "    def __init__(self, X):\n",
    "        super().__init__()\n",
    "        self.SocialSig = bilinearImputation(X=X)                \n",
    "        self.conv2d = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.maxPool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "        self.block1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            torch.nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            torch.nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "        self.block2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            torch.nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            torch.nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)#,\n",
    "            # torch.nn.Sequential(\n",
    "            #     torch.nn.Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
    "            #     torch.nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            # )\n",
    "        )\n",
    "        self.block3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            torch.nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            torch.nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "        self.seqBlock1 = torch.nn.Sequential(self.block1, self.block1)\n",
    "        self.seqBlock2 = torch.nn.Sequential(self.block2, self.block3)\n",
    "    \n",
    "\n",
    "        self.block4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            torch.nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            torch.nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            #   (downsample): Sequential(\n",
    "            #     (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "            #     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            #   )\n",
    "        )\n",
    "        self.block5 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            torch.nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            torch.nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "        self.seqBlock3 = torch.nn.Sequential(self.block4, self.block5)\n",
    "\n",
    "        self.block6 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "                torch.nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                torch.nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "                torch.nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            #   (downsample): Sequential(\n",
    "            #     (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "            #     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            #   )\n",
    "            )\n",
    "        self.block7 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            torch.nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            torch.nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "\n",
    "        self.seqBlock4 = torch.nn.Sequential(self.block6, self.block7)\n",
    "\n",
    "        self.linear = torch.nn.Linear(51200, 100)\n",
    "\n",
    "        \n",
    "    def forward(self, X, epoch):\n",
    "        out = self.SocialSig(X) # OUT:  torch.Size([100, 1, 10, 10])\n",
    "\n",
    "        # print(out)\n",
    "        # tmp = out.clone()\n",
    "        # print('SHAPE: ', tmp[0].flatten().shape)\n",
    "        pd.DataFrame(out.clone()[0].flatten()).to_csv(\"./figs/im\" + str(epoch) + \".csv\")\n",
    "\n",
    "        out = self.conv2d(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxPool(out)\n",
    "        out = self.seqBlock1(out)\n",
    "        out = self.seqBlock2(out)\n",
    "        out = self.seqBlock3(out)\n",
    "        out = self.seqBlock4(out)\n",
    "        out = self.relu(out)\n",
    "        out = out.flatten()\n",
    "        out = self.linear(out)\n",
    "        # print(\"OUT: \", out.shape)\n",
    "        # print(\"OUT: \", out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Load our Data\n",
    "from sklearn import preprocessing\n",
    "devSet = pd.read_csv(\"us_migration.csv\")\n",
    "devSet = devSet.loc[:, ~devSet.columns.str.contains('^Unnamed')]\n",
    "devSet = devSet.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "devSet = devSet.dropna(axis=1)\n",
    "\n",
    "y = torch.Tensor(devSet['US_MIG_05_10'].values)\n",
    "X = devSet.loc[:, devSet.columns != \"US_MIG_05_10\"].values\n",
    "\n",
    "mMScale = preprocessing.MinMaxScaler()\n",
    "X = mMScale.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y - 'number_moved'\n",
    "#x - 'everything else that is or can be represented as a float.'\n",
    "\n",
    "####### Build and fit the Model\n",
    "model = SocialSigNet(X=X)\n",
    "lr = 1e-6\n",
    "batchSize = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_function(param, grad, loss, learning_rate):\n",
    "    # print(grad.mean(axis = 1))\n",
    "    return param - learning_rate * grad.mean(axis = 0)[0]\n",
    "\n",
    "\n",
    "def mae(real, pred):\n",
    "    return torch.abs(real - pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "EPOCH:  0\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
      "        28., 29.], requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107695616.0      MAE:  732.6861572265625\n",
      "\n",
      "\n",
      "EPOCH:  1\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([4.4054e-04, 1.0004e+00, 2.0004e+00, 3.0004e+00, 4.0004e+00, 5.0004e+00,\n",
      "        6.0004e+00, 7.0004e+00, 8.0004e+00, 9.0004e+00, 1.0000e+01, 1.1000e+01,\n",
      "        1.2000e+01, 1.3000e+01, 1.4000e+01, 1.5000e+01, 1.6000e+01, 1.7000e+01,\n",
      "        1.8000e+01, 1.9000e+01, 2.0000e+01, 2.1000e+01, 2.2000e+01, 2.3000e+01,\n",
      "        2.4000e+01, 2.5000e+01, 2.6000e+01, 2.7000e+01, 2.8000e+01, 2.9000e+01],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      102635792.0      MAE:  711.9801635742188\n",
      "\n",
      "\n",
      "EPOCH:  2\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([3.0336e-03, 1.0030e+00, 2.0030e+00, 3.0030e+00, 4.0030e+00, 5.0030e+00,\n",
      "        6.0030e+00, 7.0030e+00, 8.0030e+00, 9.0030e+00, 1.0003e+01, 1.1003e+01,\n",
      "        1.2003e+01, 1.3003e+01, 1.4003e+01, 1.5003e+01, 1.6003e+01, 1.7003e+01,\n",
      "        1.8003e+01, 1.9003e+01, 2.0003e+01, 2.1003e+01, 2.2003e+01, 2.3003e+01,\n",
      "        2.4003e+01, 2.5003e+01, 2.6003e+01, 2.7003e+01, 2.8003e+01, 2.9003e+01],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      90280224.0      MAE:  648.1048583984375\n",
      "\n",
      "\n",
      "EPOCH:  3\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([8.4520e-03, 1.0085e+00, 2.0085e+00, 3.0085e+00, 4.0085e+00, 5.0085e+00,\n",
      "        6.0085e+00, 7.0085e+00, 8.0085e+00, 9.0085e+00, 1.0008e+01, 1.1008e+01,\n",
      "        1.2008e+01, 1.3008e+01, 1.4008e+01, 1.5008e+01, 1.6008e+01, 1.7008e+01,\n",
      "        1.8008e+01, 1.9008e+01, 2.0008e+01, 2.1008e+01, 2.2008e+01, 2.3008e+01,\n",
      "        2.4008e+01, 2.5008e+01, 2.6008e+01, 2.7008e+01, 2.8008e+01, 2.9008e+01],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      77782552.0      MAE:  587.5472412109375\n",
      "\n",
      "\n",
      "EPOCH:  4\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([ 0.1432,  1.1432,  2.1432,  3.1432,  4.1432,  5.1432,  6.1432,  7.1432,\n",
      "         8.1432,  9.1432, 10.1432, 11.1432, 12.1432, 13.1432, 14.1432, 15.1432,\n",
      "        16.1432, 17.1432, 18.1432, 19.1432, 20.1432, 21.1432, 22.1432, 23.1432,\n",
      "        24.1432, 25.1432, 26.1432, 27.1432, 28.1432, 29.1432],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      568643520.0      MAE:  2331.825927734375\n",
      "\n",
      "\n",
      "EPOCH:  5\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      424753952.0      MAE:  1959.8065185546875\n",
      "\n",
      "\n",
      "EPOCH:  6\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      129011480.0      MAE:  887.5413208007812\n",
      "\n",
      "\n",
      "EPOCH:  7\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107706848.0      MAE:  732.868896484375\n",
      "\n",
      "\n",
      "EPOCH:  8\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107706416.0      MAE:  732.8674926757812\n",
      "\n",
      "\n",
      "EPOCH:  9\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107706000.0      MAE:  732.8660278320312\n",
      "\n",
      "\n",
      "EPOCH:  10\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107705568.0      MAE:  732.864501953125\n",
      "\n",
      "\n",
      "EPOCH:  11\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107705120.0      MAE:  732.863037109375\n",
      "\n",
      "\n",
      "EPOCH:  12\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107704696.0      MAE:  732.8616333007812\n",
      "\n",
      "\n",
      "EPOCH:  13\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107704264.0      MAE:  732.860107421875\n",
      "\n",
      "\n",
      "EPOCH:  14\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107703840.0      MAE:  732.858642578125\n",
      "\n",
      "\n",
      "EPOCH:  15\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107703408.0      MAE:  732.8572387695312\n",
      "\n",
      "\n",
      "EPOCH:  16\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107702968.0      MAE:  732.8557739257812\n",
      "\n",
      "\n",
      "EPOCH:  17\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107702552.0      MAE:  732.8543090820312\n",
      "\n",
      "\n",
      "EPOCH:  18\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107702120.0      MAE:  732.852783203125\n",
      "\n",
      "\n",
      "EPOCH:  19\n",
      "    W at beginning:  Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)\n",
      "tensor([[0.2898, 0.1509, 0.0190,  ..., 0.1573, 0.1314, 0.0966],\n",
      "        [0.2899, 0.1219, 0.0467,  ..., 0.1205, 0.0576, 0.1563],\n",
      "        [0.2899, 0.0849, 0.0434,  ..., 0.0958, 0.0000, 0.0581],\n",
      "        ...,\n",
      "        [0.3544, 0.1835, 0.0631,  ..., 0.1078, 1.0000, 0.0559],\n",
      "        [0.3544, 0.1527, 0.0137,  ..., 0.1609, 0.0822, 0.1063],\n",
      "        [0.3545, 0.0551, 0.0601,  ..., 0.0545, 0.1000, 0.0278]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "    Loss:      107701680.0      MAE:  732.8513793945312\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(20):\n",
    "    #Batches\n",
    "    # batchObs = random.sample(range(0, len(y)), batchSize)\n",
    "    batchObs = [i for i in range(0, 100)]\n",
    "    modelX = X[batchObs]\n",
    "    # print(modelX.shape)\n",
    "    modelX = torch.tensor(list(modelX), requires_grad = True, dtype = torch.float32)\n",
    "    modely = torch.tensor(y[batchObs], dtype = torch.float32)  # MADE A CHANGE HERE \n",
    "    \n",
    "    \n",
    "    print(\"EPOCH: \", t)\n",
    "    y_pred = model(modelX, t)\n",
    "    # print(y_pred)\n",
    "    loss = criterion(y_pred, modely)  \n",
    "    # print()  \n",
    "    print(\"    Loss:     \", loss.item(), \"     MAE: \", mae(y_pred, modely).item())\n",
    "    \n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    grad = torch.autograd.grad(outputs=loss, inputs=modelX, retain_graph = True)\n",
    "    # print(\"    GRADIENT: \", grad[0][0].shape)\n",
    "    # print(\"    GRADIENT: \", grad)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # https://discuss.pytorch.org/t/updatation-of-parameters-without-using-optimizer-step/34244/4\n",
    "    with torch.no_grad():\n",
    "        for p in model.parameters():\n",
    "            # print(\"    In with:        \", p.data)\n",
    "            new_val = update_function(p, grad[0], loss, lr)\n",
    "            # print(\"NEW WEIGHTS: \", new_val)\n",
    "            p.copy_(new_val)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.1735, -0.2011, -0.1756, -0.1974, -0.1698, -0.1929, -0.2003, -0.1969,\n",
       "        -0.2097, -0.1358, -0.2016, -0.2019, -0.1959, -0.1927, -0.1798, -0.1978,\n",
       "        -0.1887, -0.1976, -0.2014, -0.1940, -0.1928, -0.1872, -0.2041, -0.1832,\n",
       "        -0.2051, -0.2015, -0.2017, -0.2099, -0.2004, -0.1937, -0.1982, -0.1738,\n",
       "        -0.1959, -0.1914, -0.1941, -0.2033, -0.2000, -0.2033, -0.2012, -0.2023,\n",
       "        -0.1967, -0.2017, -0.1936, -0.1774, -0.1942, -0.1984, -0.1822, -0.1529,\n",
       "        -0.1442, -0.1627, -0.1926, -0.1968, -0.1772, -0.1567, -0.1723, -0.1866,\n",
       "        -0.1679, -0.1798, -0.1608, -0.1117, -0.1890, -0.1612, -0.1749, -0.1954,\n",
       "        -0.1441, -0.1364, -0.1941, -0.1715, -0.1929, -0.1890, -0.1848, -0.1864,\n",
       "        -0.1797, -0.1961, -0.1444, -0.1394, -0.1523, -0.1873, -0.1710, -0.1721,\n",
       "        -0.1860, -0.1787, -0.1713, -0.1899, -0.1755, -0.1787, -0.2040, -0.1528,\n",
       "        -0.1877, -0.1954, -0.1753, -0.1862, -0.1675, -0.0787, -0.1842, -0.0269,\n",
       "        -0.1935, -0.1968, -0.1899, -0.1995], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 385
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 961.,  154.,  905.,  225., 1071.,  337.,  204.,  320.,   61., 2063.,\n",
       "         125.,  170.,  378.,  318.,  777.,  201.,  427.,  187.,  133.,  304.,\n",
       "         479.,  464.,  163.,  772.,   57.,  219.,  211.,   80.,  267.,  307.,\n",
       "         198., 1048.,  229.,  413.,  460.,  121.,  255.,  147.,  136.,  157.,\n",
       "         268.,  295.,  342.,  780.,  494.,  222.,  802., 1507., 1634., 1183.,\n",
       "         522.,  281.,  943., 1354.,  984.,  619., 1175.,  897., 1201., 2672.,\n",
       "         568., 1363.,  830.,  436., 1862., 2042.,  350.,  951.,  481.,  556.,\n",
       "         592.,  515.,  694.,  344., 1777., 1974., 1581.,  519., 1025., 1053.,\n",
       "         719.,  708., 1072.,  440.,  861.,  723.,  138., 1419.,  542.,  287.,\n",
       "         996.,  511., 1119., 3623.,  567., 4955.,  500.,  278.,  392.,  225.])"
      ]
     },
     "metadata": {},
     "execution_count": 386
    }
   ],
   "source": [
    "modely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model.parameters\n",
      "<bound method Module.parameters of SocialSigNet(\n",
      "  (SocialSig): bilinearImputation()\n",
      "  (conv2d): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxPool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (seqBlock1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (seqBlock2): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (block4): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block5): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (seqBlock3): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (block6): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block7): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (seqBlock4): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=51200, out_features=100, bias=True)\n",
      ")>\n",
      "SSParam\n",
      "[Parameter containing:\n",
      "tensor([-0.2056,  0.7944,  1.7944,  2.7944,  3.7944,  4.7944,  5.7944,  6.7944,\n",
      "         7.7944,  8.7944,  9.7944, 10.7944, 11.7944, 12.7944, 13.7944, 14.7944,\n",
      "        15.7944, 16.7944, 17.7944, 18.7944, 19.7944, 20.7944, 21.7944, 22.7944,\n",
      "        23.7944, 24.7944, 25.7944, 26.7944, 27.7944, 28.7944],\n",
      "       requires_grad=True)]\n",
      "is_leaf\n",
      "True\n",
      "gradfn\n",
      "None\n",
      "Grad\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Model.parameters\")\n",
    "print(model.parameters)\n",
    "print(\"SSParam\")\n",
    "print(list(model.SocialSig.parameters()))\n",
    "print(\"is_leaf\")\n",
    "print(list(model.SocialSig.parameters())[0].is_leaf)\n",
    "print(\"gradfn\")\n",
    "print(list(model.SocialSig.parameters())[0].grad_fn)\n",
    "print(\"Grad\")\n",
    "print(list(model.SocialSig.parameters())[0].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(best_epoch):\n",
    "    df = pd.read_csv(\"./figs/im\" + str(best_epoch) + \".csv\")\n",
    "    df[\"0\"] = df[\"0\"].str.split(\"(\").str[1].str.split(\",\").str[0].astype(float)\n",
    "    plt.imshow(np.reshape(np.array(df[\"0\"]), (10, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 245.2025 248.518125\" width=\"245.2025pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-15T16:10:03.387498</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 245.2025 248.518125 \nL 245.2025 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 20.5625 224.64 \nL 238.0025 224.64 \nL 238.0025 7.2 \nL 20.5625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p8ec84cca85)\">\n    <image height=\"218\" id=\"image3cd2886c60\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"20.5625\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAD6UlEQVR4nO3cvY0kVRSA0VfTNfwYeGhXCIGBIAJSIARiQISHiYlHGhABoBVolpnpwsZcqe7XGjgngKun1/3V8+72zfbtsYBRd7c+APwfCA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0COyX169ufYab27ZtZvDlMjP3fh8Ze+xD5x24h9++/vj0mWut9eazmbfHiwYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGgf36+etbn+GdHAMLq47LzPfm2GfmPn40swXr6cOZ8z59cP6P9uq7X06fudZaP3/148hcLxoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoENjX0/XWZ3gn28CnYbse5w9dax3PM3d7f8ycd/9raEnR5fzlPL/+8MXpM9da68tPvx+Z60WDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg8C+PT7f+gy3N/S52bbztz+ttdbd26eRuWMG7uGTnx5OnznJiwYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGgX17eHvrM/x3DW3BGjN13oG52345feZaax2Xoc1lI1OBfxEaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBDY15s/RwZvL2ij0rob+t5M3cFl6Lwv6B6O6/X0mWuttQ3dgRcNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQL79fc/RgaPbcG6XE4fud3vp89ca611/97I2O39mbnreszMHbA9D/2/hnjRICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoPAfjw+zUy+G1qecgwskHl+Pn/mWmv9/Tgy9nh4GJk7tlBp6r8wYZt5e7xoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBDY13VmA9RxDG0+up6/BWtgr9aLtE1tqxraLPWSuAEICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CPwD++RFRNYzXfcAAAAASUVORK5CYII=\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m7c6a399f63\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.4345\" xlink:href=\"#m7c6a399f63\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(28.25325 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"74.9225\" xlink:href=\"#m7c6a399f63\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(71.74125 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"118.4105\" xlink:href=\"#m7c6a399f63\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(115.22925 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"161.8985\" xlink:href=\"#m7c6a399f63\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(158.71725 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"205.3865\" xlink:href=\"#m7c6a399f63\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(202.20525 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"md8aee12eda\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#md8aee12eda\" y=\"18.072\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(7.2 21.871219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#md8aee12eda\" y=\"61.56\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 2 -->\n      <g transform=\"translate(7.2 65.359219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#md8aee12eda\" y=\"105.048\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 4 -->\n      <g transform=\"translate(7.2 108.847219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#md8aee12eda\" y=\"148.536\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 6 -->\n      <g transform=\"translate(7.2 152.335219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#md8aee12eda\" y=\"192.024\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 8 -->\n      <g transform=\"translate(7.2 195.823219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 20.5625 224.64 \nL 20.5625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 238.0025 224.64 \nL 238.0025 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 20.5625 224.64 \nL 238.0025 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 20.5625 7.2 \nL 238.0025 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p8ec84cca85\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"20.5625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "show_image(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 245.2025 248.518125\" width=\"245.2025pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-15T16:10:03.532814</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 245.2025 248.518125 \nL 245.2025 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 20.5625 224.64 \nL 238.0025 224.64 \nL 238.0025 7.2 \nL 20.5625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p416fcfe9eb)\">\n    <image height=\"218\" id=\"imagead149c2a5a\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"20.5625\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAD6UlEQVR4nO3cvY0kVRSA0VfTNfwYeGhXCIGBIAJSIARiQISHiYlHGhABoBVolpnpwsZcqe7XGjgngKun1/3V8+72zfbtsYBRd7c+APwfCA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0COyX169ufYab27ZtZvDlMjP3fh8Ze+xD5x24h9++/vj0mWut9eazmbfHiwYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGgf36+etbn+GdHAMLq47LzPfm2GfmPn40swXr6cOZ8z59cP6P9uq7X06fudZaP3/148hcLxoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoENjX0/XWZ3gn28CnYbse5w9dax3PM3d7f8ycd/9raEnR5fzlPL/+8MXpM9da68tPvx+Z60WDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg8C+PT7f+gy3N/S52bbztz+ttdbd26eRuWMG7uGTnx5OnznJiwYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGgX17eHvrM/x3DW3BGjN13oG52345feZaax2Xoc1lI1OBfxEaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBDY15s/RwZvL2ij0rob+t5M3cFl6Lwv6B6O6/X0mWuttQ3dgRcNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQL79fc/RgaPbcG6XE4fud3vp89ca611/97I2O39mbnreszMHbA9D/2/hnjRICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoPAfjw+zUy+G1qecgwskHl+Pn/mWmv9/Tgy9nh4GJk7tlBp6r8wYZt5e7xoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBDY13VmA9RxDG0+up6/BWtgr9aLtE1tqxraLPWSuAEICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CPwD++RFRNYzXfcAAAAASUVORK5CYII=\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"md11cbfee72\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.4345\" xlink:href=\"#md11cbfee72\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(28.25325 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"74.9225\" xlink:href=\"#md11cbfee72\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(71.74125 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"118.4105\" xlink:href=\"#md11cbfee72\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(115.22925 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"161.8985\" xlink:href=\"#md11cbfee72\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(158.71725 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"205.3865\" xlink:href=\"#md11cbfee72\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(202.20525 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m35d777fdb7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m35d777fdb7\" y=\"18.072\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(7.2 21.871219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m35d777fdb7\" y=\"61.56\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 2 -->\n      <g transform=\"translate(7.2 65.359219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m35d777fdb7\" y=\"105.048\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 4 -->\n      <g transform=\"translate(7.2 108.847219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m35d777fdb7\" y=\"148.536\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 6 -->\n      <g transform=\"translate(7.2 152.335219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m35d777fdb7\" y=\"192.024\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 8 -->\n      <g transform=\"translate(7.2 195.823219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 20.5625 224.64 \nL 20.5625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 238.0025 224.64 \nL 238.0025 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 20.5625 224.64 \nL 238.0025 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 20.5625 7.2 \nL 238.0025 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p416fcfe9eb\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"20.5625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAK1UlEQVR4nO3dzY9ddR3H8c9n7szQBxBIdGPb2C6IpiEazARBEhbUhYgBFy4gwUQ3XShPxoSgG/8Bg7ogJg1CTCCyqCwIIYiJunBhw1BIoK0kTdFSHstC1PowHftxMWNSW2bu6e35eeZ+eb+SJp17Lz++PTPvOXdO7/3VSQSgjpmhBwDQL6IGiiFqoBiiBoohaqCY2RaLzvuSbNLWFktj2njqFp4K/8wpLeWfH3gQmkS9SVv1Oe/pf2E3+kSaJyyteIbPWQu/P/3smvd9uI8MUBBRA8UQNVAMUQPFEDVQDFEDxXSK2vYXbb9q+6jtB1oPBWByY6O2PZL0kKSbJe2WdIft3a0HAzCZLmfqayUdTXIsyZKkJyTd1nYsAJPqEvU2Sa+f9fGJ1dv+h+29thdtL57Wv/qaD8AF6u1CWZJ9SRaSLMzpkr6WBXCBukT9hqQdZ328ffU2ABtQl6ifl3SV7V225yXdLumptmMBmNTYd2klWbZ9l6RfShpJeiTJoeaTAZhIp7deJnlG0jONZwHQA15RBhRD1EAxRA0UQ9RAMUQNFNNk40FJ0syo9yWbbWI3ajBrq00SZxp9H25wDKSWx2GKdhNtsEmi3197Tc7UQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxbXYTteW5/pdutjNli91EG/z5JUlz802W9SVt1lWrz1kL07RD6d/YTRT40CBqoBiiBoohaqAYogaKIWqgGKIGihkbte0dtn9j+7DtQ7bv/X8MBmAyXV4hsSzpO0kO2r5M0gu2f5XkcOPZAExg7Jk6yVtJDq7+/q+Sjkja1nowAJO5oNcy2t4p6RpJBz7gvr2S9krSJm3pYzYAE+h8ocz2pZJ+Iem+JH859/4k+5IsJFmY86Y+ZwRwATpFbXtOK0E/nuTJtiMBuBhdrn5b0k8lHUnyYPuRAFyMLmfqGyR9TdJNtl9a/fWlxnMBmNDYC2VJfidpit5oCny48YoyoBiiBoohaqAYogaKabI7nkcjzVxxef/rttrErsW6M42+XzbbfLHRvFN0HDJNx2CdNTlTA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFNNlNVKMZ6bKtvS+b3lecQq12E21lmnaAnR31v6akjBrMus6fnzM1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UEznqG2PbL9o++mWAwG4OBdypr5X0pFWgwDoR6eobW+XdIukh9uOA+BidT1T/0jS/ZLOrPUA23ttL9peXPr3P/qYDcAExkZt+8uS3k3ywnqPS7IvyUKShfnR5t4GBHBhupypb5B0q+0/SnpC0k22H2s6FYCJjY06yXeTbE+yU9Ltkn6d5M7mkwGYCH9PDRRzQe+nTvJbSb9tMgmAXnCmBoohaqAYogaKIWqgGKIGimmzm+jMjLLpkiZLT41W3y6nbTfRVhoch0zRsc06o3KmBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKabKbaCxlbtRi6TZafGtrtDNlZtqse2a+zecrs23OGxn1fxze+3SbHXBPbTvT+5r/+uHany/O1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxnaK2fYXt/bb/YPuI7etbDwZgMl1ffPJjSc8m+arteUlbGs4E4CKMjdr25ZJulPR1SUqyJGmp7VgAJtXl6fcuSSclPWr7RdsP29567oNs77W9aHvx9PLfex8UQDddop6V9FlJP0lyjaRTkh4490FJ9iVZSLIwN8uzc2AoXaI+IelEkgOrH+/XSuQANqCxUSd5W9Lrtj+5etMeSYebTgVgYl2vft8t6fHVK9/HJH2j3UgALkanqJO8JGmh7SgA+sAryoBiiBoohqiBYogaKIaogWKa7CYqWWq0i2QLabBBZ0aNdtFsdFxPX9bmS2F5c5t5lzf1/0n7xFeO9b6mJD111bO9r3ntz06ued/0lAegE6IGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGimmy25yXTmvm+Dstlp4adoPdDCVpNGqy7Pxcm40HM9tm3hbH4WR29r6mJF2945u9r/nauw+ueR9naqAYogaKIWqgGKIGiiFqoBiiBoohaqCYTlHb/rbtQ7Zfsf1z25taDwZgMmOjtr1N0j2SFpJcLWkk6fbWgwGYTNen37OSNtuelbRF0pvtRgJwMcZGneQNST+QdFzSW5LeT/LcuY+zvdf2ou3FpTP/6H9SAJ10efp9paTbJO2S9HFJW23fee7jkuxLspBkYX5mc/+TAuiky9PvL0h6LcnJJKclPSnp823HAjCpLlEfl3Sd7S1eeevRHklH2o4FYFJdfqY+IGm/pIOSXl79b/Y1ngvAhDq9iTbJ9yV9v/EsAHrAK8qAYogaKIaogWKIGiiGqIFimmwhmeVl/fudd1ssDTTzkVePtlm3wZoncmrN+zhTA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFOEn/i9onJf2pw0M/Kum93gdoZ5rmnaZZpemadyPM+okkH/ugO5pE3ZXtxSQLgw1wgaZp3mmaVZqueTf6rDz9BoohaqCYoaOetn+8fprmnaZZpemad0PPOujP1AD6N/SZGkDPiBooZrCobX/R9qu2j9p+YKg5xrG9w/ZvbB+2fcj2vUPP1IXtke0XbT899CzrsX2F7f22/2D7iO3rh55pPba/vfp18Irtn9veNPRM5xokatsjSQ9JulnSbkl32N49xCwdLEv6TpLdkq6T9K0NPOvZ7pV0ZOghOvixpGeTfErSZ7SBZ7a9TdI9khaSXC1pJOn2Yac631Bn6mslHU1yLMmSpCck3TbQLOtK8laSg6u//6tWvui2DTvV+mxvl3SLpIeHnmU9ti+XdKOkn0pSkqUkfx50qPFmJW22PStpi6Q3B57nPENFvU3S62d9fEIbPBRJsr1T0jWSDgw8yjg/knS/pDMDzzHOLkknJT26+qPCw7a3Dj3UWpK8IekHko5LekvS+0meG3aq83GhrCPbl0r6haT7kvxl6HnWYvvLkt5N8sLQs3QwK+mzkn6S5BpJpyRt5OsrV2rlGeUuSR+XtNX2ncNOdb6hon5D0o6zPt6+etuGZHtOK0E/nuTJoecZ4wZJt9r+o1Z+rLnJ9mPDjrSmE5JOJPnvM5/9Wol8o/qCpNeSnExyWtKTkj4/8EznGSrq5yVdZXuX7XmtXGx4aqBZ1mXbWvmZ70iSB4eeZ5wk302yPclOrRzXXyfZcGcTSUrytqTXbX9y9aY9kg4PONI4xyVdZ3vL6tfFHm3AC3uzQ/xPkyzbvkvSL7VyBfGRJIeGmKWDGyR9TdLLtl9ave17SZ4ZbqRS7pb0+Oo392OSvjHwPGtKcsD2fkkHtfK3Ii9qA75klJeJAsVwoQwohqiBYogaKIaogWKIGiiGqIFiiBoo5j8bYzFwhFbqhwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "show_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 245.2025 248.518125\" width=\"245.2025pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-15T16:10:03.679840</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 245.2025 248.518125 \nL 245.2025 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 20.5625 224.64 \nL 238.0025 224.64 \nL 238.0025 7.2 \nL 20.5625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p9d0d9db57e)\">\n    <image height=\"218\" id=\"imagebb2f88f3df\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"20.5625\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAD6UlEQVR4nO3cvY0kVRSA0VfTNfwYeGhXCIGBIAJSIARiQISHiYlHGhABoBVolpnpwsZcqe7XGjgngKun1/3V8+72zfbtsYBRd7c+APwfCA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0COyX169ufYab27ZtZvDlMjP3fh8Ze+xD5x24h9++/vj0mWut9eazmbfHiwYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGgf36+etbn+GdHAMLq47LzPfm2GfmPn40swXr6cOZ8z59cP6P9uq7X06fudZaP3/148hcLxoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoENjX0/XWZ3gn28CnYbse5w9dax3PM3d7f8ycd/9raEnR5fzlPL/+8MXpM9da68tPvx+Z60WDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg8C+PT7f+gy3N/S52bbztz+ttdbd26eRuWMG7uGTnx5OnznJiwYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGgX17eHvrM/x3DW3BGjN13oG52345feZaax2Xoc1lI1OBfxEaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBDY15s/RwZvL2ij0rob+t5M3cFl6Lwv6B6O6/X0mWuttQ3dgRcNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQL79fc/RgaPbcG6XE4fud3vp89ca611/97I2O39mbnreszMHbA9D/2/hnjRICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoPAfjw+zUy+G1qecgwskHl+Pn/mWmv9/Tgy9nh4GJk7tlBp6r8wYZt5e7xoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBDY13VmA9RxDG0+up6/BWtgr9aLtE1tqxraLPWSuAEICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CPwD++RFRNYzXfcAAAAASUVORK5CYII=\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m368801d693\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.4345\" xlink:href=\"#m368801d693\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(28.25325 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"74.9225\" xlink:href=\"#m368801d693\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(71.74125 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"118.4105\" xlink:href=\"#m368801d693\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(115.22925 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"161.8985\" xlink:href=\"#m368801d693\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(158.71725 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"205.3865\" xlink:href=\"#m368801d693\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(202.20525 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m29368c7a5e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m29368c7a5e\" y=\"18.072\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(7.2 21.871219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m29368c7a5e\" y=\"61.56\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 2 -->\n      <g transform=\"translate(7.2 65.359219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m29368c7a5e\" y=\"105.048\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 4 -->\n      <g transform=\"translate(7.2 108.847219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m29368c7a5e\" y=\"148.536\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 6 -->\n      <g transform=\"translate(7.2 152.335219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m29368c7a5e\" y=\"192.024\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 8 -->\n      <g transform=\"translate(7.2 195.823219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 20.5625 224.64 \nL 20.5625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 238.0025 224.64 \nL 238.0025 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 20.5625 224.64 \nL 238.0025 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 20.5625 7.2 \nL 238.0025 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9d0d9db57e\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"20.5625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "show_image(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('data442': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8e3a21d38ab9816cf2a4fb5b70910b2de32092d7fedca6365d5651d786256744"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}