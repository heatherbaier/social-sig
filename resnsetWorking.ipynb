{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "caoe",
   "display_name": "caoe",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from sklearn import tree\n",
    "import rasterio as rio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import sklearn\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "import math\n",
    "import copy\n",
    "\n",
    "import resnet18\n",
    "importlib.reload(resnet18)\n",
    "from helpers import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = dataLoader(\"./final_pics\", \"./us_migration.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = d.train_val_split(split = .80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y - 'number_moved'\n",
    "#x - 'everything else that is or can be represented as a float.'\n",
    "\n",
    "####### Build and fit the Model\n",
    "lr = 1e-5\n",
    "batchSize = 50\n",
    "model = resnet18.resnet18(outDim = batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, lr, batchSize, num_epochs):\n",
    "\n",
    "    losses = []\n",
    "    maes = []\n",
    "    best_mae = 100000000\n",
    "    i_to_print = torch.tensor([0,1,2,3,4])\n",
    "\n",
    "    for t in range(num_epochs):\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "\n",
    "            if phase == 'train':\n",
    "\n",
    "                #Batches\n",
    "                batchObs = random.sample(range(0, len(y_train)), batchSize)\n",
    "                # print(batchObs)\n",
    "                modelX = [x_train[i] for i in batchObs]\n",
    "                modelX = torch.tensor(list(modelX), requires_grad = True, dtype = torch.float32)\n",
    "                modely = torch.tensor([y_train[i] for i in batchObs], dtype = torch.float32)  # MADE A CHANGE HERE \n",
    "                y_pred = model(modelX, t)\n",
    "                # print(y_pred)\n",
    "                \n",
    "                loss = criterion(y_pred, modely)  \n",
    "                \n",
    "                # Zero gradients, perform a backward pass, and update the weights.\n",
    "                optimizer.zero_grad()\n",
    "                grad = torch.autograd.grad(outputs=loss, inputs=modelX, retain_graph = True)\n",
    "                # print(\"    GRADIENT: \", grad[0][0].shape)\n",
    "                # print(\"    GRADIENT: \", grad[0])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # https://discuss.pytorch.org/t/updatation-of-parameters-without-using-optimizer-step/34244/4\n",
    "                # with torch.no_grad():\n",
    "                #     for name, p in model.named_parameters():\n",
    "                #         if name == 'SocialSig.W':\n",
    "                #         # print(\"    In with:        \", p.data)\n",
    "                #             new_val = socialSigLayers.update_function(p, grad[0], loss, lr)\n",
    "                #         # print(\"NEW WEIGHTS: \", new_val)\n",
    "                #             p.copy_(new_val)\n",
    "\n",
    "                print(\"EPOCH: \", t)\n",
    "                # print(modely)\n",
    "                epoch_mae = mae(y_pred, modely).item()\n",
    "                print(\"    TRAIN    Loss:   \", loss.item(), \"     MAE:   \", epoch_mae)\n",
    "                # print(\"    Train Preds:     \", torch.index_select(y_pred, 0, i_to_print))\n",
    "                # print(\"    Train True:       \", torch.index_select(modely, 0, i_to_print))\n",
    "\n",
    "            if phase == 'val':\n",
    "\n",
    "                #Batches\n",
    "                batchObs = random.sample(range(0, len(y_train)), batchSize)\n",
    "                # print(batchObs)\n",
    "                modelX = [x_train[i] for i in batchObs]\n",
    "                modelX = torch.tensor(list(modelX), requires_grad = True, dtype = torch.float32)\n",
    "                modely = torch.tensor([y_train[i] for i in batchObs], dtype = torch.float32)  # MADE A CHANGE HERE \n",
    "                \n",
    "                # Perform evaluations of the batch predictions\n",
    "                y_pred = model(modelX, t)\n",
    "                \n",
    "                loss = criterion(y_pred, modely)  \n",
    "                epoch_mae = mae(y_pred, modely).item()\n",
    "                print(\"    VAL      Loss:   \", loss.item(), \"     MAE:   \", epoch_mae)\n",
    "                # print(\"    Val Preds:       \", torch.index_select(y_pred, 0, i_to_print))\n",
    "                # print(\"    Val True:       \", torch.index_select(modely, 0, i_to_print))\n",
    "\n",
    "                if epoch_mae < best_mae:\n",
    "                    \n",
    "                    best_mae = epoch_mae\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    model_name = './models/test_Epoch' + str(t) + '.sav'\n",
    "                    pickle.dump(model, open(model_name, 'wb'))\n",
    "\n",
    "                losses.append(loss.item())\n",
    "                maes.append(epoch_mae)\n",
    "                \n",
    "        print(\"\\n\")\n",
    "\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "    print(\"Best MAE: \", best_mae)\n",
    "\n",
    "    # print(best_model_wts)\n",
    "\n",
    "    # return model.load_state_dict(best_model_wts)\n",
    "    return best_model_wts, losses, maes, y_pred, modely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1254400 and 250880x10)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-429-fd0cdd5029bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_model_wts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-428-9f29db0c955e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, lr, batchSize, num_epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mmodelX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mmodely\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatchObs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# MADE A CHANGE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;31m# print(y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/caoe/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CAOE/sig/resnet18.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, epoch)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/caoe/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/caoe/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/caoe/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1254400 and 250880x10)"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "best_model_wts, losses, maes, ypreds, ytrue = train_model(model, criterion, optimizer, lr, batchSize, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 418
    }
   ],
   "source": [
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pred_dataset(x_val, model, batch_size, y_val):\n",
    "    preds, true_vals = [], []\n",
    "    lst = [i for i in range(0, len(x_val))]\n",
    "    batches = [lst[i:i+batch_size] for i in range(0, len(lst), batch_size)]\n",
    "    batches = [i for i in batches if len(i) == batch_size]\n",
    "    n = len(batches)\n",
    "    for subset in range(0, n):\n",
    "        cur_xval = [x_val[i] for i in batches[subset]]\n",
    "        modelX = torch.tensor(list(cur_xval), requires_grad = True, dtype = torch.float32)\n",
    "        cur_preds = model(modelX, 400)\n",
    "        preds.append(list(cur_preds.detach().numpy()))\n",
    "        true_vals.append([y_val[i] for i in batches[subset]])\n",
    "\n",
    "        print(\"Done with batch \", str(subset), \" out of \", str(n))\n",
    "\n",
    "    true_vals = [item for sublist in true_vals for item in sublist]\n",
    "    preds = [item for sublist in preds for item in sublist]\n",
    "\n",
    "    to_ret = pd.DataFrame()\n",
    "    to_ret['id'] = [i for i in range(0, len(true_vals))]\n",
    "    to_ret['pred'] = preds\n",
    "    to_ret['true_val'] = true_vals\n",
    "    \n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done with batch  0  out of  46\n",
      "Done with batch  1  out of  46\n",
      "Done with batch  2  out of  46\n",
      "Done with batch  3  out of  46\n",
      "Done with batch  4  out of  46\n",
      "Done with batch  5  out of  46\n",
      "Done with batch  6  out of  46\n",
      "Done with batch  7  out of  46\n",
      "Done with batch  8  out of  46\n",
      "Done with batch  9  out of  46\n",
      "Done with batch  10  out of  46\n",
      "Done with batch  11  out of  46\n",
      "Done with batch  12  out of  46\n",
      "Done with batch  13  out of  46\n",
      "Done with batch  14  out of  46\n",
      "Done with batch  15  out of  46\n",
      "Done with batch  16  out of  46\n",
      "Done with batch  17  out of  46\n",
      "Done with batch  18  out of  46\n",
      "Done with batch  19  out of  46\n",
      "Done with batch  20  out of  46\n",
      "Done with batch  21  out of  46\n",
      "Done with batch  22  out of  46\n",
      "Done with batch  23  out of  46\n",
      "Done with batch  24  out of  46\n",
      "Done with batch  25  out of  46\n",
      "Done with batch  26  out of  46\n",
      "Done with batch  27  out of  46\n",
      "Done with batch  28  out of  46\n",
      "Done with batch  29  out of  46\n",
      "Done with batch  30  out of  46\n",
      "Done with batch  31  out of  46\n",
      "Done with batch  32  out of  46\n",
      "Done with batch  33  out of  46\n",
      "Done with batch  34  out of  46\n",
      "Done with batch  35  out of  46\n",
      "Done with batch  36  out of  46\n",
      "Done with batch  37  out of  46\n",
      "Done with batch  38  out of  46\n",
      "Done with batch  39  out of  46\n",
      "Done with batch  40  out of  46\n",
      "Done with batch  41  out of  46\n",
      "Done with batch  42  out of  46\n",
      "Done with batch  43  out of  46\n",
      "Done with batch  44  out of  46\n",
      "Done with batch  45  out of  46\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id        pred  true_val\n",
       "0   0  131.377502        84\n",
       "1   1   57.921864       619\n",
       "2   2  150.939316        99\n",
       "3   3   98.996971       335\n",
       "4   4   91.957092       242"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>pred</th>\n      <th>true_val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>131.377502</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>57.921864</td>\n      <td>619</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>150.939316</td>\n      <td>99</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>98.996971</td>\n      <td>335</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>91.957092</td>\n      <td>242</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 420
    }
   ],
   "source": [
    "preds_df = pred_dataset(x_val, model, 10, y_val)\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "118.9601009617681"
      ]
     },
     "metadata": {},
     "execution_count": 421
    }
   ],
   "source": [
    "allocation_error = abs((sum(preds_df['true_val']) - sum(preds_df['pred'])) / len(preds_df['pred']))\n",
    "allocation_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "54721.64644241333"
      ]
     },
     "metadata": {},
     "execution_count": 422
    }
   ],
   "source": [
    "quantity_error = abs(sum(preds_df['true_val']) - sum(preds_df['pred']))\n",
    "quantity_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "215.12865516828455"
      ]
     },
     "metadata": {},
     "execution_count": 423
    }
   ],
   "source": [
    "mae = mean_absolute_error(preds_df['true_val'], preds_df['pred'])\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.4757216542315956e+16"
      ]
     },
     "metadata": {},
     "execution_count": 424
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(preds_df['true_val'], preds_df['pred'])\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.1594528511954303"
      ]
     },
     "metadata": {},
     "execution_count": 425
    }
   ],
   "source": [
    "r2 = r2_score(preds_df['true_val'], preds_df['pred'])\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}